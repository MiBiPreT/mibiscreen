{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documention for <code>mibiscreen</code> python package","text":"<p>A Python package for prediction and analysis in Microbiome based Remediation. Developed as part of the MiBiRem toolbox for Bioremediation.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install mibiscreen from GitHub repository, do:</p> <pre><code>git clone git@github.com:MiBiPreT/mibiscreen.git\ncd mibiscreen\npython -m pip mibiscreen .\n</code></pre>"},{"location":"application/data_pipeline_template/","title":"Data pipeline","text":"<p>In the following you could read all the steps to create data pipeline for your project: </p>"},{"location":"application/data_pipeline_template/#1-data-ingestion-collection-of-raw-data","title":"1. Data Ingestion (Collection of Raw Data)","text":"<p>This is the first stage, where raw data is gathered from various sources and ingested into the pipeline. It can be structured as per our case (databases, CSV files, APIs, Excels).</p>"},{"location":"application/data_pipeline_template/#examples","title":"Examples:","text":"<ul> <li>Batch Data: importing a CSV file of site data regularly like once a day.</li> <li>API Data: Pulling real-time data streams from the API.</li> <li>Database Extraction: Replicating data from a MySQL database to our own database.</li> </ul>"},{"location":"application/data_pipeline_template/#2-data-preprocessing-cleaning-and-standardization","title":"2. Data Preprocessing (Cleaning and Standardization)","text":"<p>Before analysis, raw data is often messy and inconsistent. This step ensures data quality, removes duplicates, corrects errors, and formats it for the next processes. This step can be done manually or automated by code.</p>"},{"location":"application/data_pipeline_template/#tasks-in-this-stage","title":"Tasks in this stage:","text":"<ul> <li>Check format like the headings and units per column</li> <li>Handling missing values (e.g., filling gaps with averages)</li> <li>Data deduplication (removing repeated records)</li> <li>Converting different formats (e.g., date formats across multiple sources, unit conversion)</li> <li>Encoding Data: Create identifiers for the samples name based on their location and country</li> <li>Normalization (converting text values to lowercase, trimming spaces, etc.)</li> </ul>"},{"location":"application/data_pipeline_template/#examples_1","title":"Examples:","text":"<ul> <li>Standardizing dates from different sources (e.g., converting MM-DD-YYYY to YYYY-MM-DD)</li> <li>Convert units to SI units(e.g., pound to Kg, ft to m)</li> <li>Removing duplicate sample records from different sources</li> <li>Filtering out irrelevant data (e.g., the columns that we don\u2019t need)</li> <li>Sample name identifier example: NL_GRI_W_1</li> </ul>"},{"location":"application/data_pipeline_template/#3-data-transformation-processing-and-enrichment","title":"3. Data Transformation (Processing and Enrichment)","text":"<p>In this step, data is converted into a useful format, enriched with additional information, or aggregated for reporting. This step also can be done manually or automated by code.</p>"},{"location":"application/data_pipeline_template/#common-tasks-in-this-stage","title":"Common tasks in this stage:","text":"<ul> <li>Joining Data: Merging datasets from multiple sources</li> <li>Data Enrichment: Calculating new values from initial data</li> </ul>"},{"location":"application/data_pipeline_template/#examples_2","title":"Examples:","text":"<ul> <li>Merging site measurments data with lab analyized data in one csv file</li> <li>Calculating isotop ratio according to Raleigh equation</li> </ul>"},{"location":"application/data_pipeline_template/#4-data-storage-centralized-data-repository","title":"4. Data Storage (Centralized Data Repository)","text":"<p>Once data is transformed, it is stored in an appropriate system depending on the use case.</p>"},{"location":"application/data_pipeline_template/#types-of-storage","title":"Types of Storage:","text":"<ul> <li>Databases like UU YODA, MySQL</li> <li>GitHub repository</li> </ul>"},{"location":"application/data_pipeline_template/#examples_3","title":"Examples:","text":"<ul> <li>Storing processed data in YODA</li> </ul>"},{"location":"application/data_pipeline_template/#5-data-validation-monitoring-for-each-data-analysis-module-quality-control","title":"5. Data Validation &amp; Monitoring for Each Data Analysis Module  (Quality Control)","text":"<p>This stage ensures that processed data is accurate, complete, and meets requirements to run different analysis.</p>"},{"location":"application/data_pipeline_template/#common-checks","title":"Common Checks:","text":"<ul> <li>Schema validation (ensuring expected columns, required input data or calculated parameters exists)</li> <li>Anomaly detection (flagging unexpected values)</li> <li>Data freshness checks (ensuring updates occur within expected timeframes)</li> </ul>"},{"location":"application/data_pipeline_template/#examples_4","title":"Examples:","text":"<ul> <li>Checking if any contaminant are missing calculated isotope ratios baed on Raliegh equation exist for isoptoppe analysis. </li> <li> <p>Validating all the concentration values are positive numbers.  </p> </li> <li> <p>Monitoring real-time streaming data for sudden spikes in API errors (if we want to recive redox data of Grift park constructed wetlan from online server)</p> </li> </ul>"},{"location":"application/data_pipeline_template/#6-data-analytics-delivery-insights-output","title":"6. Data Analytics &amp; Delivery (Insights &amp; Output)","text":"<p>At this stage, we extract insights from processed data, either through graphs or reports.</p>"},{"location":"application/data_pipeline_template/#examples_5","title":"Examples:","text":"<ul> <li>Graph: Visualize na_analysis data as traffic lights plotted for each sample</li> <li>Graph: creat Rayleigh plots</li> <li>Reports: prepare TAUW report</li> <li>APIs that serve the processed data to other services or researchers</li> </ul>"},{"location":"application/data_pipeline_template/#end-to-end-example-of-the-data-pipeline","title":"End-to-End Example of the Data Pipeline","text":"<p>After installing mibipret, the following python code can be executed from the root directory of the mibipret repository.</p>"},{"location":"application/data_pipeline_template/#1-ingestion","title":"1. Ingestion:","text":"<pre><code>from mibipret.data.load_data import load_csv\nfrom mibipret.data.load_data import load_excel\n\n# load data from csv file\ngriftpark_file_path = \"./examples/ex01_Griftpark/grift_BTEXIIN.csv\ndata_raw,units = load_csv(griftpark_file_path,verbose=False)\n\n# load data from excel file per sheet \namersfoort_file_path = \"./examples/ex02_Amersfoort/amersfoort.xlsx\nenvironment_raw,units = load_excel(amersfoort_file_path, sheet_name = 'environment', verbose = False)\n</code></pre>"},{"location":"application/data_pipeline_template/#2-preprocessingcleaning-and-standardization","title":"2. Preprocessing:(Cleaning and Standardization)","text":"<p>Runs all checks on data, i.e. column names (check_columns()), data format (check_data_frame()), units (check_units()), names (standard_names()) and values (check_values()) in one go and returns transformed data with standard column names and valueas in numerical type where possible. Data is reduced to those columns containing known quantities if reduce=true.</p> <pre><code>from mibipret.data.check_data import standardize\ndata, units = standardize(data_raw, reduce = True, verbose=False)\n</code></pre>"},{"location":"application/data_pipeline_template/#3-transformationprocessing-and-enrichment","title":"3. Transformation:(processing and enrichment)","text":"<p>For NA screening, stochiometric equations are used to analyze electron balance, here is how to perform NA screening step by step:</p>"},{"location":"application/data_pipeline_template/#calculation-of-number-of-electrons-for-reduction","title":"Calculation of number of electrons for reduction","text":"<p>Returns pandas-Series with total amount of electron reductors per well in [mmol e-/l]: <pre><code>import mibipret.analysis.sample.screening_NA as na\ntot_reduct = na.reductors(data,verbose = True,ea_group = 'ONSFe')\n</code></pre></p>"},{"location":"application/data_pipeline_template/#calculation-of-number-of-electrons-needed-for-oxidation","title":"Calculation of number of electrons needed for oxidation","text":"<p>Returns pandas-Series with total amount of oxidators per well in [mmol e-/l]:</p> <pre><code>tot_oxi = na.oxidators(data,verbose = True, contaminant_group='BTEXIIN')\n</code></pre>"},{"location":"application/data_pipeline_template/#calculation-of-number-of-electron-balance","title":"Calculation of number of electron balance","text":"<p>Returns pandas-Series with ratio of reductors to oxidators. If value below 1, available electrons for reduction are not sufficient for reaction and thus NA is potentially not taking place: <pre><code>e_bal = na.electron_balance(data,verbose = True)\n</code></pre></p>"},{"location":"application/data_pipeline_template/#evaluation-of-intervention-threshold-exceedance","title":"Evaluation of intervention threshold exceedance","text":""},{"location":"application/data_pipeline_template/#calculation-of-total-concentration-of-contaminantsspecified-group-of-contaminants","title":"Calculation of total concentration of contaminants/specified group of contaminants","text":"<p>Returns pandas-Series with total concentrations of contaminants per well in [ug/l]: <pre><code>tot_cont = na.total_contaminant_concentration(data,verbose = True,contaminant_group='BTEXIIN')\n</code></pre> If you want to perform complete NA screening and evaluation of intervention threshold exceedance in one go: <pre><code>data_na = na.screening_NA(data,verbose = True)\n</code></pre> It is also possible to run full NA screening with results added to data using argument (inplace = True): <pre><code>na.screening_NA(data,inplace = True,verbose = False)\n</code></pre></p>"},{"location":"application/data_pipeline_template/#4-storage","title":"4. Storage:","text":"<p>Warning</p> <p>Mibipret does not have support for file storage</p>"},{"location":"application/data_pipeline_template/#5-validation-monitoring-for-each-data-analysis-module","title":"5. Validation &amp; Monitoring for Each Data Analysis Module","text":"<p>we use the <code>options</code> function to check what types of analyses/modeling/visualization/reports we can do on the dataset if func argument is provided, it will check whether this function is possible and if not what else is needed</p> <p>Warning</p> <p>This is intended behaviour but has not been implemented yet.</p> <pre><code>mibipret.decision_support.options(st_sample_data, func=mibipret.visualize.traffic3d)\n\n# To perform mibipret.visualize.traffic3d you need to run mibipret.analysis.na_screening\n# the workflow requires the following columns: [x,y, depth]\n# Row 4-19 and 28-39 have these columns defined, you can apply the function on these rows.\n</code></pre>"},{"location":"application/data_pipeline_template/#6-analytics","title":"6. Analytics:","text":""},{"location":"application/data_pipeline_template/#calculation-of-traffic-light-based-on-electron-balance","title":"Calculation of \u201ctraffic light\u201d based on electron balance","text":"<p>Returns pandas-Series with traffic light (red/yellow/green) if NA is taking place based on electron balance. Red corresponds to a electron balance below 1 where available electrons for reduction are not sufficient and thus NA is potentially not taking place:</p> <pre><code>na_traffic = na.NA_traffic(data,verbose = True)\n</code></pre>"},{"location":"application/data_pipeline_template/#calculation-of-traffic-light-for-threshold-exceedance","title":"Calculation of \u201ctraffic light\u201d for threshold exceedance","text":"<p>Returns pandas-DataFrame (similar to input data, including well specification) with intervention threshold exceedance analysis: traffic light if well requires intervention (red/yellow/green) number of contaminants exceeding the intervention value list of contaminants above the threshold of intervention</p> <pre><code>na_intervention = na.thresholds_for_intervention(data,verbose = True,contaminant_group='BTEXIIN')\ndisplay(na_intervention)\n</code></pre>"},{"location":"application/data_pipeline_template/#activity-plot","title":"Activity plot","text":"<p>Create activity plot linking contaminant concentration to metabolite occurence based on NA screening.</p> <pre><code>from mibipret.visualize.activity import activity\nfig, ax = activity(data)\n</code></pre>"},{"location":"development/development/","title":"<code>mibiscreen</code> developer documentation","text":""},{"location":"development/development/#development-install","title":"Development install","text":"<pre><code># Create a virtual environment, e.g. with\npython -m venv env\n\n# activate virtual environment\nsource env/bin/activate\n\n# make sure to have a recent version of pip and setuptools\npython -m pip install --upgrade pip setuptools\n\n# (from the project root directory)\n# install mibiscreen as an editable package\npython -m pip install --no-cache-dir --editable .\n# install development dependencies\npython -m pip install --no-cache-dir --editable .[dev]\n</code></pre> <p>Afterwards check that the install directory is present in the <code>PATH</code> environment variable.</p>"},{"location":"development/development/#running-the-tests","title":"Running the tests","text":"<p>There are two ways to run tests.</p> <p>The first way requires an activated virtual environment with the development tools installed:</p> <pre><code>pytest -v\n</code></pre> <p>The second is to use <code>tox</code>, which can be installed separately (e.g. with <code>pip install tox</code>), i.e. not necessarily inside the virtual environment you use for installing <code>mibiscreen</code>, but then builds the necessary virtual environments itself by simply running:</p> <pre><code>tox\n</code></pre> <p>Testing with <code>tox</code> allows for keeping the testing environment separate from your development environment. The development environment will typically accumulate (old) packages during development that interfere with testing; this problem is avoided by testing with <code>tox</code>.</p>"},{"location":"development/development/#test-coverage","title":"Test coverage","text":"<p>In addition to just running the tests to see if they pass, they can be used for coverage statistics, i.e. to determine how much of the package\u2019s code is actually executed during tests. In an activated virtual environment with the development tools installed, inside the package directory, run:</p> <pre><code>coverage run\n</code></pre> <p>This runs tests and stores the result in a <code>.coverage</code> file. To see the results on the command line, run</p> <pre><code>coverage report\n</code></pre> <p><code>coverage</code> can also generate output in HTML and other formats; see <code>coverage help</code> for more information.</p>"},{"location":"development/development/#running-linters-locally","title":"Running linters locally","text":"<p>For linting and sorting imports we will use ruff. Running the linters requires an  activated virtual environment with the development tools installed.</p> <pre><code># linter\nruff check .\n\n# linter with automatic fixing\nruff check . --fix\n</code></pre> <p>To fix readability of your code style you can use yapf.</p> <p>You can enable automatic linting with <code>ruff</code> on commit by enabling the git hook from <code>.githooks/pre-commit</code>, like so:</p> <pre><code>git config --local core.hooksPath .githooks\n</code></pre>"},{"location":"development/development/#testing-docs-locally","title":"Testing docs locally","text":"<p>To build the documentation locally, first make sure <code>mkdocs</code> and its dependencies are installed: <pre><code>python -m pip install .[doc]\n</code></pre></p> <p>Then you can build the documentation and serve it locally with <pre><code>mkdocs serve\n</code></pre></p> <p>This will return a URL (e.g. <code>http://127.0.0.1:8000/mibiscreen/</code>) where the docs site can be viewed.</p>"},{"location":"development/development/#versioning","title":"Versioning","text":"<p>Bumping the version across all files is done with bump-my-version, e.g.</p> <pre><code>bump-my-version major  # bumps from e.g. 0.3.2 to 1.0.0\nbump-my-version minor  # bumps from e.g. 0.3.2 to 0.4.0\nbump-my-version patch  # bumps from e.g. 0.3.2 to 0.3.3\n</code></pre>"},{"location":"development/development/#making-a-release","title":"Making a release","text":"<p>This section describes how to make a release in 3 parts:</p> <ol> <li>preparation</li> <li>making a release on PyPI</li> <li>making a release on GitHub</li> </ol>"},{"location":"development/development/#13-preparation","title":"(1/3) Preparation","text":"<ol> <li>Verify that the information in CITATION.cff is correct.</li> <li>Make sure the version has been updated.</li> <li>Run the unit tests with <code>pytest -v</code></li> </ol>"},{"location":"development/development/#23-pypi","title":"(2/3) PyPI","text":"<p>In a new terminal:</p> <pre><code># OPTIONAL: prepare a new directory with fresh git clone to ensure the release\n# has the state of origin/main branch\ncd $(mktemp -d mibiscreen.XXXXXX)\ngit clone git@github.com:MiBiPreT/mibiscreen .\n\n# make sure to have a recent version of pip and the publishing dependencies\npython -m pip install --upgrade pip\npython -m pip install .[publishing]\n\n# create the source distribution and the wheel\npython -m build\n\n# upload to test pypi instance (requires credentials)\npython -m twine upload --repository testpypi dist/*\n</code></pre> <p>Visit https://test.pypi.org/</p> <p>and verify that your package was uploaded successfully. Keep the terminal open, we\u2019ll need it later.</p> <p>In a new terminal, without an activated virtual environment or an env directory:</p> <pre><code>cd $(mktemp -d mibiscreen-test.XXXXXX)\n\n# prepare a clean virtual environment and activate it\npython -m venv env\nsource env/bin/activate\n\n# make sure to have a recent version of pip and setuptools\npython -m pip install --upgrade pip\n\n# install from test pypi instance:\npython -m pip -v install --no-cache-dir \\\n--index-url https://test.pypi.org/simple/ \\\n--extra-index-url https://pypi.org/simple mibiscreen\n</code></pre> <p>Check that the package works as it should when installed from pypitest.</p> <p>Then upload to pypi.org with:</p> <pre><code># Back to the first terminal,\n# FINAL STEP: upload to PyPI (requires credentials)\npython -m twine upload dist/*\n</code></pre>"},{"location":"development/development/#33-github","title":"(3/3) GitHub","text":"<p>Don\u2019t forget to also make a release on GitHub. If your repository uses the GitHub-Zenodo integration this will also trigger Zenodo into making a snapshot of your repository and sticking a DOI on it.</p>"},{"location":"introduction/introduction/","title":"Introduction","text":""},{"location":"introduction/introduction/#general","title":"General","text":"<p>Contaminated sites pose a risk to humans and the environment. Innovative cleaning technologies are needed to remediate these sites and remove contaminants such as petroleum hydrocarbons (PHC), cyanides and hexachlorocyclohexane (HCH).</p> <p>Conventional methods of contaminated site remediation are often costly and upkeep intensive. Bioremediation is an alternative of particular interest, as it degrades contaminants on-site. Assessment of ongoing biodegradation is an important step to check the feasibility for bioremediation. Similarly, modeling the fate of contaminants is key for understanding the processes involved and predicting bioremediation in the field. </p> <p>Detailed data analysis of field measurements, such as sampling data on contaminant concentrations, environmental conditions (such as pH), geo-chemical parameters (such as concentrations of oxygen, nitrate, sulfate etc) is the starting point for identifying the status of the site, assessing feasibility of bioremediation and designing remediation options. For instance, multivariate statistical analysis of field observation data can provide guidance on feasibility of bioremediation by evaluating the amount of biodegradation taking place. </p> <p>Numerical simulation can provide valuable knowledge on the processes occurring on site, like groundwater flow and contaminant transport including geo-chemical processes like adsorption and biodegradation. Combining simulations on groundwater flow, contaminant transport and chemical reactions allows making predictions on amounts, locations and time scales of biodegradation as well as measures of bioremediation. A combination of (statistical) data-analysis of observational data with predictions by numerical simulations, is a promising option for decision support on bioremediation for field sites. </p> <p>The purpose of this package is to process, analyse and visualize biogeochemical and hydrogeological (field) data relevant for biodegredation and bioremediation. <code>mibiret</code> is the central repository within the GitHub organization MiBiPreT for data handling, basic data analysis and diagnostic plotting.</p>"},{"location":"introduction/introduction/#mibirem","title":"MIBIREM","text":"<p>MIBIREM - Innovative technological toolbox for bioremediation is a EU funded consortium project by 12 international partners all over Europe working together to develop an Innovative technological toolbox for bioremediation. The project will develop molecular methods for the monitoring, isolation, cultivation and subsequent deposition of whole microbiomes. The toolbox will also include the methodology for the improvement of specific microbiome functions, including evolution and enrichment. The performance of selected microbiomes will be tested under real field conditions. The <code>mibipret</code> package is part of this toolbox.</p>"},{"location":"introduction/introduction/#bioremediation","title":"Bioremediation","text":"<p>Bioremediation uses living organisms (including bacteria) to digest and neutralize environmental contaminants. Like the microbiome in the gut, which supports the body in digesting food, microbiomes at contaminated sites can degrade organic contaminant in soil and groundwater.</p> <p>Processes relevant for general biodegradation and bioremediation prediction are:</p> <ul> <li>hydrogeological flow and transport: this includes groundwater flow driven by hydraulic gradients, advective transport of contaminant, diffusion and dispersion</li> <li>transformation and phase transition processes: dissolution, volatilization, adsorption/retardation, decay</li> <li>biochemical processes: chemical reaction and microbial degradation</li> <li>microbiome evolution: spatial distribution and temporal development of bacteria actively degrading contaminants under various and/or changing environmental conditions.</li> </ul> <p>Modeling all these processes at the same time, requires a high level of model detail, spatially resolved parameter information and knowledge on initial and boundary conditions. This is typically not feasible in the field. Thus, we follow the approach to select and combine most relevant processes and have modeling sub-modules (repositories within the MiBiPreT organization) which can be used for data analysis and predictive modeling of individual or combined processes. At the same time, modules are designed to allow for coupling of processes and (modeling) sub-modules at a advanced stage of tool development.</p>"},{"location":"introduction/introduction/#example-field-data","title":"Example Field data","text":"<p>We gathered field data from two sites for development and testing of implemented routines on field sample data:</p> <ul> <li>the Griftpark site [Faber, 2023]</li> <li>the VetGas Amersfoort site [van Leeuwen et al., 2020, 2022]</li> </ul> <p>Both sites are heavily contaminated with petroleum hydrocarbons. Sampling campaigns and extensive sample analysis produced data on contaminant concentrations, geochemical conditions, metabolite concentrations, and isotope data. </p>"},{"location":"introduction/introduction/#structure","title":"Structure","text":"<p>The core elements and folders for users of <code>mibipret</code> are:</p> <ul> <li>The folder <code>mibipret</code> contains the main functionality split up into folders for:<ul> <li><code>data</code></li> <li><code>analysis</code> </li> <li><code>visualization</code></li> </ul> </li> <li>The folder <code>examples</code> contains example workflows in the form of Jupyter-Notebooks outlining application of functionality on example data from:</li> <li>Griftpark: <code>ex01_Griftpark</code></li> <li>Vetgas Amersfoort: <code>ex02_Amersfoort</code></li> </ul>"},{"location":"introduction/introduction/#references","title":"References","text":"<p>Faber, S. C. (2023). Field investigations and reactive transport modelling of biodegradingcoal tar compounds at a complex former manufactured gas plant. Utrecht Studies in Earth Sciences (USES), 289.</p> <p>van Leeuwen, J. A., N. Hartog, J. Gerritse, C. Gallacher, R. Helmus, O. Brock, J. R. Parsons, and S. M. Hassanizadeh, (2020) The dissolution and microbial degradation of mobile aromatic hydrocarbons from a Pintsch gas tar DNAPL source zone, Science of The Total Environment, 722, 137,797.</p> <p>van Leeuwen, J. A., J. Gerritse, N. Hartog, S. Ertl, J. R. Parsons, and S. M. Hassanizadeh, (2022) Anaerobic degradation of benzene and other aromatic hydrocarbons in a tar-derived plume: Nitrate versus iron reducing conditions, Journal of Contaminant Hydrology, 248, 104,006</p>"},{"location":"methods/concentrations/","title":"<code>mibiscreen</code> Concentrations","text":""},{"location":"methods/concentrations/#general","title":"General","text":"<p><code>concentration</code> provides tools for analysis of concentrations values of: * contaminants * electron acceptors/geochemical quantities * metabolites </p>"},{"location":"methods/concentrations/#total-concentration","title":"Total concentration","text":"<p>The routine <code>total_concentration()</code> provides the option to calculate, per sample, the sum of concentrations for a selection of quantities, e.g. the total concentration of all contaminants, all BTEX contaminants, all metabolites (if they are provided as single data frame), etc.. </p>"},{"location":"methods/concentrations/#threshold-values","title":"Threshold values","text":"<p>The routine <code>total_count()</code> provides the option to calculate, per sample, the number of quantities exceeding a self-defined threshold value (by default zero) for a list of quantities provided, e.g. for all contaminants, all BTEX contaminants, all metabolites (if they are provided as single data frame), etc.. Note that the same threshold values is applied to all quantities. </p> <p>The routine <code>thresholds_for_intervention()</code> provides the option to determine which contaminants exceed regulatory threshold values. Here, threshold values differ per contaminant. At the moment, only the regulatory threshold values for The Netherlands are implemented, and only for the group of contaminants: BTEXIIN (benzene, toluene, ethylbenzene, xylene, indene, indane, naphtalen). </p>"},{"location":"methods/concentrations/#concentration-plots","title":"Concentration plots","text":"<p>To be added: visualization of results of concentration analysis.</p>"},{"location":"methods/data/","title":"<code>mibiscreen</code> Data handling","text":""},{"location":"methods/data/#general","title":"General","text":"<p>We designed data handling for field sample data typical for biodegradation processes. This data includes</p> <ul> <li>sample specification data, </li> <li>contaminant concentrations, focusing on petroleum hydrocarbons, </li> <li>hydrogeochemical data and habitat conditions, e.g. redox potential, pH, electron acceptor concentrations, such as oxygen, nitrate, sulfate</li> <li>microbiome data (i.e. the occurrence of DNA and functional genes), </li> <li>metabolite data (i.e. intermediate products of the degradation process)</li> <li>measurements on stable isotope fractions (particularly for hydrogen and carbon within the sample and/or of individual contaminant)</li> </ul> <p>Data has to be provided in a standardized form. Data transformation is implemented in functions performing:</p> <ul> <li>loading data from csv or excel files</li> <li>check of input data on <ul> <li>correct units provided</li> <li>numerical values</li> </ul> </li> <li>standardisation, e.g. of column names to standard names</li> <li>selection of data</li> </ul> <p>A workflow of data handling is illustrated for the Griftpark data in a jupyter-notebook <code>\\examples\\ex01_Griftpark\\example_01_grift_data.ipynb</code>. </p>"},{"location":"methods/na_screening/","title":"<code>mibiscreen</code> Natural Attenuation Screening","text":""},{"location":"methods/na_screening/#general","title":"General","text":"<p><code>na_screening</code> provides tools for data analysis regarding ongoing biodegradation. Outcome of this quick-scan serve as starting point for evaluating if natural attenuation is a feasible strategy for remediation. The quick-scan is based on technical and scientific analysis of existing data. Goal is to determine whether natural attenuation is occurring and to identify what type of additional data is further necessary to prognosticate long-term behavior of a contaminant plume. The tools for the NA screening are based on the First traffic light: Quick scan of historical data as part of the NOBIS-report of Sinke et al., 2001. The output can serve as decision support, while decisions on whether NA can be applied remain with problem owners and authorities. Relevant aspects in these discussions and decisions, such as political and practical considerations are not included here.</p>"},{"location":"methods/na_screening/#what-is-natural-attenuation-na","title":"What is Natural Attenuation (NA)?","text":"<p>Natural Attenuation (NA) or monitored natural attenuation (MAN) is a strategy for clean-up of contaminated groundwater based on allowing naturally occurring processes to reduce the toxic potential of contaminants. NA does not apply engineered solutions but builds on the recognition that certain subsurface pollutants can degrade naturally without human intervention under appropriate conditions.</p> <p>Processes involved in NA:</p> <ul> <li>hydro(geo)logy: Dilution of contaminant concentrations by spatial spreading due to dispersion and diffusion.</li> <li>biology: Reduction of contaminant mass by microbial degradation. </li> <li>geochemistry: Immobilization of contaminants due to chemical reactions and adsorption.</li> </ul> <p>All processes are linked as geochemical composition of the domain impacts microbial activity (availability of electron acceptors for their metabolism) and hydrogeological transport changes concentrations of contaminant, but also electron acceptors in space and time. </p>"},{"location":"methods/na_screening/#assessment-criteria","title":"Assessment criteria","text":"<p>To decide if NA is suitable as remediation strategy, the most important questions that need to be answered are:</p> <ol> <li>Does natural degradation of the contamination occur?</li> <li>Is the degradation fast enough compared to the tolerated spread?</li> <li>Is the process complete or is there stagnation in the long term?</li> </ol> <p>If natural degradation of the contamination occurs, it is expected that a stable end situation will be reached in the short or long term. A remediation objective for the subsurface is for instance formulating a period of 30 years to achieve a stable end situation. Specifically, reaching acceptable concentrations of contaminants in the groundwater which are no threat to existing vulnerable objects and/or major impediments to the current or future use of the location or the environment. In many cases, but not always necessarily, there will be a sustainable equilibrium between supply and natural degradation and/or retention. Reaching a stable end situation my include temporary plume expansion. Modeling can help to evaluate for how long a plume will continue to expand until a stationary situation is reached. For the application of natural degradation, this has to be put in relation to the question if degradation is fast enough compared to the tolerated spread. If degradation stagnates, e.g. due to depletion of electron acceptors, with contaminant concentration levels exceeding acceptable levels, then NA is not a sustainable remediation strategy. </p>"},{"location":"methods/na_screening/#na-as-remediation-strategy","title":"NA as remediation strategy","text":"<p>The purpose of this NA screening is to estimate the physical possibilities for (monitored) NA as a remediation strategy at the earliest possible stage and with the least possible resources/expenses. Simple criteria are used to determine whether location-specific remediation objectives can be achieved within a reasonable time frame.</p>"},{"location":"methods/na_screening/#traffic-light-principle","title":"Traffic light principle","text":"<p>Data analysis provides decision support information in the form of traffic lights. They reflect the chances on natural attenuation as a remediation option: </p> <ul> <li>good with green light, </li> <li>fair chance with yellow light, </li> <li>no chance with a red light. </li> </ul> <p>In case of a yellow traffic light, additional information is needed.</p>"},{"location":"methods/na_screening/#requirements","title":"Requirements","text":"<p>Analysis is based on historical location data. If these are available through reports, no additional effort or costs need to be made. Required information and requirements for sampling setup:</p> <ul> <li>position of the sampling tubes: measurements must be taken both for the source and in a path parallel to the direction of flow</li> <li>measured parameters: contaminant concentrations and the redox paramters.</li> </ul> <p>Starting point is a spreadsheet/dataframe containing structured data. Raw data has to be brought into a template format with support routines provided in <code>data</code> to load, clean and standardize the data. A template spreadsheet can be found at \u2026to see how data needs to be structured.</p>"},{"location":"methods/na_screening/#traffic-light-evaluation","title":"Traffic light evaluation","text":""},{"location":"methods/na_screening/#step-1","title":"Step 1","text":"<p>For each sample location, first a distinction is made between aerobic and anaerobic conditions. Aerobic conditions are more favorable for the BTEX degradation process, which means that the possibilities for natural degradation are good. Thus, aerobic conditions get green light. Anaerobic conditions are less favorable for the degradation process, further evaluation is done in step 2.</p>"},{"location":"methods/na_screening/#step-2","title":"Step 2","text":"<p>Possibilities for natural attenuation are limited under anaerobic conditions. Monitoring is necessary to determine whether natural degradation occurs. Thus, determine</p> <ul> <li>concentrations over time </li> <li>redox over time and/or space</li> </ul>"},{"location":"methods/na_screening/#step-3","title":"Step 3","text":"<p>The traffic light assessment is not given per well, but for the entire location since it involves considerations of trends.  Traffic light is determined based on:</p> <ul> <li>type of contaminant</li> <li>whether concentrations decrease over time or </li> <li>whether a relationship exists between BTEX and the redox conditions</li> </ul> <p>If the concentrations clearly decrease over time, or if the redox clearly changes over time and/or space, there is a chance that natural degradation is taking place (yellow traffic light).  If not, it must be decided that natural degradation is not a good choice (red traffic light). Benzene is very difficult to degrade under anaerobic conditions. So its behavior in relation to the other components must be monitored critically. </p>"},{"location":"methods/na_screening/#overview","title":"Overview","text":"<p>Based on the development of the concentrations over time and/or the changes in redox in space and time, the color of the traffic light at the location can be determined as:</p> plume redox and redox gradient and contamination in space and time probability of NA BTEX aerobic conditions green BTEX anaerobic conditions, no redox gradient in space or decrease in concentrations in time red BTEX anaerobic conditions, redox gradient in space: from anaerobic in the core zone to aerobic in the plume yellow BTEX anaerobic conditions, concentrations decrease in time yellow B anaerobic conditions, redox gradient in space and concentration gradient in time yellow TEX anaerobic conditions, redox gradient in space and concentration gradient in time green"},{"location":"methods/na_screening/#calculations","title":"Calculations","text":"<p>Calculation of electron balance are based on the redox reactions, including stochiometric relations:</p> <p>Electrons are consumed through reduction. The reduction reactions for oxygen, nitrate, and sulfate are:</p> <ul> <li>Oxygen: \\(4 e^- + 4 H^+ + 1 O_2 \\rightarrow  H_2 O\\)</li> <li>Nitrate: \\(5e^- + 6 H^+ + 1 NO_3^- \\rightarrow 3 H_2O + 0.5 N_2\\)</li> <li>Sulfate: \\(8e^- + 9 H^+ 1 SO_4^{2-} \\rightarrow 4H_2O + 1HS^{-}\\)</li> </ul> <p>Electrons are produced during oxidation of contaminants. Reactions included for selected, typically abundant contaminants are:</p> <ul> <li>Benzene: \\(12 H_2O + 1 C_6H_6  \\rightarrow 6CO_2 + 30 H^+ + 30e^-\\)</li> <li>Toluene: \\(14 H_2O + 1 C_7H_8  \\rightarrow 7CO_2 + 36 H^+ + 36e^-\\)</li> <li>Ethylbenzene: \\(16 H_2O + 1 C_8H_{10}  \\rightarrow 8CO_2 + 42 H^+ + 42e^-\\)</li> <li>Xylene: \\(16 H_2O + 1 C_8H_{10}  \\rightarrow 8CO_2 + 42 H^+ + 42e^-\\)</li> <li>Indene: \\(18 H_2O + 1 C_9H_{8}  \\rightarrow 9CO_2 + 44 H^+ + 44e^-\\)</li> <li>Indane: \\(18 H_2O + 1 C_9H_{10}  \\rightarrow 9CO_2 + 46 H^+ + 46e^-\\)</li> <li>Naphtalene: \\(20 H_2O + 1 C_{10}H_{8}  \\rightarrow 10CO_2 + 48 H^+ + 48e^-\\)</li> </ul> <p>Concentrations of the contaminants and redox conditions are divided by their molar mass to transform to molar concentrations. The total number of electrons is then calculated based on the stoichiometric relation for one liter of solution. Number of electrons  are added up for all reductors and oxidators per sample location.</p>"},{"location":"methods/na_screening/#visualization","title":"Visualization","text":"<p>The routine <code>activity()</code> provides a visualization of the NA screening in combination with metabolite analysis.  The activity plot shows the scatter of the total number of metabolites versus the total concentration of contaminants per sample with color coding of NA traffic lights: red/yellow/green corresponding to no natural attenuation going on (red), limited/unknown NA activity (yellow)  or active natural attenuation (green).</p>"},{"location":"methods/na_screening/#references","title":"References","text":"<p>Sinke, A., T.J. Heimovaara, H. Tonnaer, J. Ter Meer (2001); Beslissingsondersteunend systeem voor de beoordeling van natuurlijke afbraak als sanieringsvariant, NOBIS 98-1-21, Gouda</p>"},{"location":"methods/ordination/","title":"<code>mibiscreen</code> Ordination","text":""},{"location":"methods/ordination/#general","title":"General","text":"<p><code>ordination</code> provides tools for multivariate statistics to calculate and visualize  the interactions between any kind of data measured in the field, including  contaminants, environmental factors, metabolite concentration and microbiota counts. </p> <p>The general goal of ordination methods is to reduce the dimensionality of the data by  arranging it along novel axes. Typically, two axis are used that represent the  main gradients of the data. Then, the variables are evaluated by their correlation  with these new axes. For each type of data correlation a different ordination method is defined. </p> <p>Ordination methods can be subdivided in two types, unconstrained and constrained.  Unconstrained ordination methods do not use any prior information about the data  and treat each type of variable similarly. <code>ordination</code> provides the unconstrained  method Principal Component Analysis (PCA). Constrained ordination uses prior  knowledge of the data, differentiating between explanatory (or independent) variables and response (or dependent) variables. <code>ordination</code> provides two constrained  ordination methods: Redundancy Analysis (RDA) and Canonical Correspondence Analysis (CCA). In the context of bioremediation, the explanatory variables are typically the environmental  variables. The response variables are typically the species variables, e.g.  microbiotic species or proxies for microbiotic species. </p> <p>Ordination methods produce scores, called loadings, for the variables and scores  for the measurement locations (referred to as sites). For constrained ordination methods,  there are separate loadings for the dependent and the independent variables.  In unconstrained ordination, there is no such separation in the loadings. </p>"},{"location":"methods/ordination/#principle-of-pca","title":"Principle of PCA","text":"<p>PCA determines the ordination axes by maximizing the amount of variance explained  by each axis. In other words, it minimizes the total amount of residual variation per axis, by minimizing the amount of variation not explained by the particular axis. This  results in a number of new axes equaling the number of variables. </p> <p>The first two axes can then be used for plotting and represent the data in two  uncorrelated directions that explain most of the variation in the data.  The dissimilarity in the data is measured as Euclidean distance. </p>"},{"location":"methods/ordination/#principle-of-constrained-ordination","title":"Principle of constrained ordination","text":"<p>Constrained ordination maximizes correlation between the independent and dependent  variables. The implemented methods RDA and CCA are canonical ordination techniques, made to  detect patterns in the dependent variables by the independent variables. </p> <p>RDA bases its axes on the same principles as PCA, by maximizing the total variance  for each axis. Like PCA, it is used when the assumed relationship between the independent and dependent variables is linear. </p> <p>CCA bases its axes on a different principle. CCA determines the axes that maximizes  the amount of dispersion/independence among variables, measured as chi-squared distance.  It is used when the assumed relationship between the data is unimodal, i.e. the data  having a probability distribution with a single peak. </p>"},{"location":"methods/ordination/#ordination-plots","title":"Ordination plots","text":"<p>Results of all ordination analysis can be visualized with <code>plot ordination_plot()</code>. It creates ordination plot based on the results of the ordination analysis routines  <code>pca()</code>, <code>cca()</code>, or <code>rda()</code>. The output of the analysis routines is streamlined and  can directly be used as input to the visualization routine.</p> <p>The two plot axis represent the two main axis identified by the ordination methods.  The first ordination axis is oriented horizontally and the second vertically.  The variable loadings are represented in the plot as arrows starting in the origin.  The site scores shown as dots represent the coordinates of the sites in the new ordination axes.</p> <p>While various axis scaling is possible, axes are generally between the minimal  value of -1 and the maximum value of 1. Positive scores or loadings indicate  positive correlation with the axis, where negative values indicate negative  correlation. For example, a variable with negative loadings for the first two  ordination axes is anticorrelated with the two largest trends in the data.</p> <p>The direction of the arrow reflecting variable loading indicates to which ordination  axis it correlates. The length of the vector is equivalent to the extent of that  correlation. Thus arrows pointing in the same direction indicate that the variable  are correlated. Arrows at an right angle to one another are uncorrelated. Arrows that point in opposite directions are anti-correlated.  A vector very close to the origin shows little to no correlation with the axes. Proximity of the site scores in the plot indicate the similarity between  the sample sites. </p> <p>Ordination plots are biplots, when two different elements are displayed, this are  e.g. variable loadings and site scores for unconstrained methods or dependent and  independent variable loadings in constrained methods. When loadings and site scores are displayed in constrained methods, they are called a triplot.</p>"},{"location":"methods/ordination/#data-transformation","title":"Data Transformation","text":"<p>There are various ways to transform the data before ordination analysis:</p> <ul> <li>centered: for each sample value of a variable \\(x_i\\) the mean of the variable over all samples \\(\\mu\\) is subtracted: \\(z_i = x_i \u2212 \\mu\\)</li> <li>standardize: \\(z_i = \\frac{x_i - \\mu}{\\sigma}\\) where \\(\\sigma\\) is the standard deviation  of the variable over all samples.</li> <li>log transformed: \\(z_i = \\log( A x_i + B)\\) where \\(A\\) and \\(B\\) scaling parameters  (typically chosen \\(A =1\\) and \\(B=1\\))</li> </ul> <p>Note that logarithmic transformation is performed before standardization or centering,  since logarithms give no solution for negative values.</p> <p>[not yet implemented]  Samples or variables can be designated as supplementary. Then the values will not be considered during ordination analysis, but their scores and loadings relative to the axes will be determined for visualization.  After performing the ordination analysis, data can be scaled or transformed again, for the purpose of plotting preferences. Scaling can be focused on either variable or sample distance. </p>"},{"location":"methods/ordination/#references","title":"References","text":"<p>Anderson, M. J., and T. J. Willis (2003), Canonical analysis of principal coordinates: A useful method of constrained ordination for ecology, Ecology, 84, 511\u2013525, doi:10.1890/0012-9658.</p> <p>Bakker, J. (2023), Diagnostic and Multivariate Statistical Tool for Bioremediation Modelling, Bsc Thesis, Department of Earth Science, Utrecht University</p> <p>ter Braak, C. J. F., (1995) Ordination, pp. 91\u2013173, 2 ed., Cambridge University Press.</p>"},{"location":"methods/overview/","title":"<code>mibiscreen</code> Methods Overview","text":"<p>Methods implemented for data analysis reflect the basic standards for data analysis and visualization of field sampling data typically gathered during field remediation efforts. This includes:</p>"},{"location":"methods/overview/#analysis-of-electron-balance-for-natural-attenuation-na-screening","title":"Analysis of electron balance for natural attenuation (NA) screening","text":"<p>Evaluating the potential and extent of biodegradation going on at a site based on relating concentrations of contaminants and electron acceptors. When concentrations of environmental conditions (oxygen, etc) and concentrations of contaminants (e.g. benzene, naphtalene) are provided in tabular (standard) form the routines <code>reductors()</code> and <code>oxidators()</code> can be used to determine the total amount electrons available for reduction and needed for oxidation are calculated per sample. The routine <code>electron_balance()</code> put that into ratio and the routine <code>NA_traffic()</code> provides a traffic light indication: Red corresponds to an electron balance below 1 where available electrons for reduction are not sufficient and thus NA is potentially not taking place. Green corresponds to an electron balance above 1 indicating that NA is potentially taking place. Yellow corresponds to a case where information is not sufficient for an evaluation. </p> <p>Results can be visualized in an activity plot.</p> <p>More on Natural Attenuation Screening</p>"},{"location":"methods/overview/#threshold-concentrations","title":"Threshold concentrations","text":"<p>Routines for identifying threshold concentrations allows evaluating if a site poses a risk and which contaminant is exceeding regulatory limits. When concentrations of contaminants are provided in tabular (standard) form the routine <code>total_contaminant_concentration()</code> provides the total amount or that of a selected subgroup of contaminants for each sample. The function <code>thresholds_for_intervention()</code> identifies for each sample those contaminants that exceed intervention thresholds. Again a traffic light system (red/yellow/green) indicates if the sample requires intervention. It further provides the number of contaminants exceeding the intervention value and a list of contaminants above the threshold of intervention.</p> <p>More on Concentrations</p>"},{"location":"methods/overview/#metabolite-analysis","title":"Metabolite analysis","text":"<p>Evaluating the occurrence of metabolites can serve as indicator for ongoing biodegradation. When metabolite data is provided in tabular (standard) form the routines <code>total_concentration()</code> and <code>total_count()</code> from the general concentration analysis can be used to determine the total amount per sample (in microgram) and the total amount of quantities exceeding a certain threshold value, e.g. exceeding zero concentration for identifying the total number of observed metabolites. The gained information can be stored in the data frame and used for visualization in an activity plot. </p> <p>More on (metabolite) Concentrations</p>"},{"location":"methods/overview/#stable-isotope-analysis","title":"Stable isotope analysis","text":"<p>Performing linear regression of stable isotope measurements, particularly of carbon 13 and deuterium for particular contaminants can provide information on changes of in the contaminant source or the occurrence of specific enzymatic degradation reactions. </p> <p>More on stable isotope analysis</p>"},{"location":"methods/overview/#multivariate-statistical-analysis-ordination","title":"Multivariate statistical analysis: Ordination","text":"<p>Workflows for multivariate statistical analysis of observational data (contaminant concentrations, habitat conditions, microbiome data, and/or metabolite data) identifying correlations between these quantities. Three ordination methods are available: Principal Component Analysis <code>pca()</code>, Canonical Correspondence Analysis <code>cca()</code> and Redundancy Analysis <code>rda()</code>.</p> <p>Output of the ordination methods is input for diagnostic plots.</p> <p>More on ordination</p>"},{"location":"methods/overview/#examples","title":"Examples","text":"<p>Example workflows of the analysis methods are implemented for the example data from the Vetgas Amersfoort site and the Griftpark field site and can be found in notebooks in the folders <code>ex01_Griftpark</code> and <code>ex02_Amersfoort</code>.</p>"},{"location":"methods/stable_isotopes/","title":"<code>mibiscreen</code> Stable Isotope Analysis","text":""},{"location":"methods/stable_isotopes/#general","title":"General","text":"<p><code>stable_isotope_regression</code> provides tools for stable isotope analysis by linear regression, including calculation and visualization  [Polerecky, 2023].</p>"},{"location":"methods/stable_isotopes/#keeling-regression","title":"Keeling regression:","text":"<p>Applying the function <code>Keeling_regression()</code> performs a linear regression linked to the Keeling plot which is an approach to identify the isotopic composition of a contaminating source from measured concentrations and isotopic composition (delta) of a target species in the mix of the source and a pool. It is based on the linear relationship of the given quantities (concentration) and delta-values which are measured over time or across a spatial interval.</p> <p>Results can be visualized with the function <code>Keeling_plot()</code>. Its input is streamlined with the output created by the analysis routine <code>Keeling_regression()</code>. The plot shows the inverse concentration data against the delta-values along the linear regression line.</p>"},{"location":"methods/stable_isotopes/#lambda-regression","title":"Lambda regression:","text":"<p>Applying the routine <code>Lambda_regression()</code> provides Lambda value based on linear regression: The Lambda values relates the \u03b413C versus \u03b42H signatures of a chemical compound. Relative changes in the ratio can indicate the occurrence of specific enzymatic degradation reactions. The analysis is based on a linear regression of the hydrogen versus carbon isotope signatures. The parameter of interest, the Lambda values is the slope of the the linear trend line. </p> <p>Results can be visualized with the routine <code>Lambda_plot()</code>. It shows the \u03b413C versus \u03b42H signatures of a chemical compound. Its input is streamlined with the output created by the analysis routine.</p>"},{"location":"methods/stable_isotopes/#rayleigh-fractionation","title":"Rayleigh fractionation","text":"<p>Rayleigh fractionation analysis using <code>Rayleigh_fractionation()</code> is a common application to characterize the removal of a substance from a finite pool using stable isotopes. It is based on the change in the isotopic composition of the pool due to different kinetics of the change in lighter and heavier isotopes. The analysis is based on a linear regression of the log-transformed concentration data against the delta-values. The parameter of interest, the kinetic fractionation factor of the removal process is the slope of the linear trend line. </p> <p>Results can be visualized with <code>Rayleigh_fractionation_plot()</code> whose input is streamlined with the output created by the analysis routine.</p>"},{"location":"methods/stable_isotopes/#references","title":"References","text":"<p>Polerecky, L. (2023), Basic quantities and applications of stable isotopes Reader accompanying Lecture 1 of the course \u201cStable Isotopes in Earth Sciences (GEO4-1443)\u201d, Utrecht University</p>"},{"location":"reference/reference_analysis/","title":"<code>mibiscreen.analysis</code> API reference","text":"<p>mibiscreen module for data analysis.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction","title":"<code>reduction</code>","text":"<p>mibiscreen module for data analysis reducing sample data.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination","title":"<code>ordination</code>","text":"<p>Routines for performing ordination statistics on sample data.</p> <p>@author: Alraune Zech, Jorrit Bakker</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.cca","title":"<code>cca(data_frame, independent_variables, dependent_variables, n_comp=2, verbose=False)</code>","text":"<p>Function that performs Canonical Correspondence Analysis.</p> <p>Function makes use of skbio.stats.ordination.CCA on the input data and gives the site scores and loadings.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.cca--input","title":"Input","text":"<pre><code>data_frame : pd.dataframe\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : list of strings\n    list with column names data to be the independent variables (=environment)\ndependent_variables : list of strings\n    list with column names data to be the dependen variables (=species)\nn_comp : int, default is 2\n    number of dimensions to return\nverbose : Boolean, The default is False.\n    Set to True to get messages in the Console about the status of the run code.\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.cca--output","title":"Output","text":"<pre><code>results : Dictionary\n    * method: name of ordination method (str)\n    * loadings_independent: loadings of independent variables (np.ndarray)\n    * loadings_dependent: loadings of dependent variables (np.ndarray)\n    * names_independent: names of independent varialbes (list of str)\n    * names_dependent: names of dependent varialbes (list of str)\n    * scores: scores (np.ndarray)\n    * sample_index: names of samples (list of str)\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/ordination.py</code> <pre><code>def cca(data_frame,\n        independent_variables,\n        dependent_variables,\n        n_comp = 2,\n        verbose = False,\n        ):\n    \"\"\"Function that performs Canonical Correspondence Analysis.\n\n    Function makes use of skbio.stats.ordination.CCA on the input data and gives\n    the site scores and loadings.\n\n    Input\n    -----\n        data_frame : pd.dataframe\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : list of strings\n            list with column names data to be the independent variables (=environment)\n        dependent_variables : list of strings\n            list with column names data to be the dependen variables (=species)\n        n_comp : int, default is 2\n            number of dimensions to return\n        verbose : Boolean, The default is False.\n            Set to True to get messages in the Console about the status of the run code.\n\n    Output\n    ------\n        results : Dictionary\n            * method: name of ordination method (str)\n            * loadings_independent: loadings of independent variables (np.ndarray)\n            * loadings_dependent: loadings of dependent variables (np.ndarray)\n            * names_independent: names of independent varialbes (list of str)\n            * names_dependent: names of dependent varialbes (list of str)\n            * scores: scores (np.ndarray)\n            * sample_index: names of samples (list of str)\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'cca()' on data\")\n        print('==============================================================')\n\n    results = constrained_ordination(data_frame,\n                           independent_variables,\n                           dependent_variables,\n                           method = 'cca',\n                           n_comp = n_comp,\n                           )\n    return results\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.constrained_ordination","title":"<code>constrained_ordination(data_frame, independent_variables, dependent_variables, method='cca', n_comp=2)</code>","text":"<p>Function that performs constrained ordination.</p> <p>Function makes use of skbio.stats.ordination on the input data and gives the scores and loadings.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.constrained_ordination--input","title":"Input","text":"<pre><code>data_frame : pd.DataFrame\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : list of strings\n   list with column names data to be the independent variables (=environment)\ndependent_variables : list of strings\n   list with column names data to be the dependen variables (=species)\nmethod : string, default is cca\n    specification of ordination method of choice. Options 'cca' &amp; 'rda'\nn_comp : int, default is 2\n    number of dimensions to return\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.constrained_ordination--output","title":"Output","text":"<pre><code>results : Dictionary\n    * method: name of ordination method (str)\n    * loadings_independent: loadings of independent variables (np.ndarray)\n    * loadings_dependent: loadings of dependent variables (np.ndarray)\n    * names_independent: names of independent varialbes (list of str)\n    * names_dependent: names of dependent varialbes (list of str)\n    * scores: scores (np.ndarray)\n    * sample_index: names of samples (list of str)\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/ordination.py</code> <pre><code>def constrained_ordination(data_frame,\n                           independent_variables,\n                           dependent_variables,\n                           method = 'cca',\n                           n_comp = 2,\n        ):\n    \"\"\"Function that performs constrained ordination.\n\n    Function makes use of skbio.stats.ordination on the input data and gives\n    the scores and loadings.\n\n    Input\n    -----\n        data_frame : pd.DataFrame\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : list of strings\n           list with column names data to be the independent variables (=environment)\n        dependent_variables : list of strings\n           list with column names data to be the dependen variables (=species)\n        method : string, default is cca\n            specification of ordination method of choice. Options 'cca' &amp; 'rda'\n        n_comp : int, default is 2\n            number of dimensions to return\n\n    Output\n    ------\n        results : Dictionary\n            * method: name of ordination method (str)\n            * loadings_independent: loadings of independent variables (np.ndarray)\n            * loadings_dependent: loadings of dependent variables (np.ndarray)\n            * names_independent: names of independent varialbes (list of str)\n            * names_dependent: names of dependent varialbes (list of str)\n            * scores: scores (np.ndarray)\n            * sample_index: names of samples (list of str)\n    \"\"\"\n    data,cols= check_data_frame(data_frame)\n\n    intersection = extract_variables(cols,\n                          independent_variables,\n                          name_variables = 'independent variables'\n                          )\n    data_independent_variables = data[intersection]\n\n    intersection = extract_variables(cols,\n                          dependent_variables,\n                          name_variables = 'dependent variables'\n                          )\n    data_dependent_variables = data[intersection]\n\n    # Checking if the dimensions of the dataframe allow for CCA\n    if (data_dependent_variables.shape[0] &lt; data_dependent_variables.shape[1]) or \\\n        (data_independent_variables.shape[0] &lt; data_independent_variables.shape[1]):\n        raise ValueError(\"Ordination method {} not possible with more variables than samples.\".format(method))\n\n    # Performing constrained ordination using function from scikit-bio.\n    if method == 'cca':\n        try:\n            sci_ordination = sciord.cca(data_dependent_variables, data_independent_variables, scaling = n_comp)\n        except(TypeError,ValueError):\n            raise TypeError(\"Not all column values are numeric values. Consider standardizing data first.\")\n    elif method == 'rda':\n        try:\n            sci_ordination = sciord.rda(data_dependent_variables, data_independent_variables, scaling = n_comp)\n        except(TypeError,ValueError):\n            raise TypeError(\"Not all column values are numeric values. Consider standardizing data first.\")\n    else:\n        raise ValueError(\"Ordination method {} not a valid option.\".format(method))\n\n    loadings_independent = sci_ordination.biplot_scores.to_numpy()[:,0:n_comp]\n    loadings_dependent = sci_ordination.features.to_numpy()[:,0:n_comp]\n    scores = sci_ordination.samples.to_numpy()[:,0:n_comp]\n\n    if loadings_independent.shape[1]&lt;n_comp:\n        raise ValueError(\"Number of dependent variables too small.\")\n\n    results = {\"method\": method,\n               \"loadings_dependent\": loadings_dependent,\n               \"loadings_independent\": loadings_independent,\n               \"names_independent\" : data_independent_variables.columns.to_list(),\n               \"names_dependent\" : data_dependent_variables.columns.to_list(),\n               \"scores\": scores,\n               \"sample_index\" : list(data.index),\n               }\n\n    return results\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.extract_variables","title":"<code>extract_variables(columns, variables, name_variables='variables')</code>","text":"<p>Checking overlap of two given list.</p> <p>Function is used for checking if a list of variables is present in the column names of a given dataframe (of quantities for data analysis)</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.extract_variables--input","title":"Input","text":"<pre><code>columns: list of strings\n    given extensive list (usually column names of a pd.DataFrame)\nvariables: list of strings\n    list of names to extract/check overlap with strings in list 'column'\nname_variables: str, default is 'variables'\n    name of type of variables given in list 'variables'\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.extract_variables--output","title":"Output","text":"<pre><code>intersection: list\n    list of strings present in both lists 'columns' and 'variables'\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/ordination.py</code> <pre><code>def extract_variables(columns,\n                      variables,\n                      name_variables = 'variables'\n                      ):\n    \"\"\"Checking overlap of two given list.\n\n    Function is used for checking if a list of variables is present in\n    the column names of a given dataframe (of quantities for data analysis)\n\n    Input\n    -----\n        columns: list of strings\n            given extensive list (usually column names of a pd.DataFrame)\n        variables: list of strings\n            list of names to extract/check overlap with strings in list 'column'\n        name_variables: str, default is 'variables'\n            name of type of variables given in list 'variables'\n\n    Output\n    ------\n        intersection: list\n            list of strings present in both lists 'columns' and 'variables'\n\n    \"\"\"\n    if isinstance(variables,list):\n        intersection = list(set(columns) &amp; set(variables))\n        remainder = list(set(variables) - set(columns))\n        if len(intersection) == 0:\n            raise ValueError(\"No column names for '{}' identified in columns of dataframe.\".format(name_variables))\n        elif len(intersection) &lt; len(variables):\n            print(\"WARNING: not all column names for '{}' are found in dataframe.\".format(name_variables))\n            print('----------------------------------------------------------------')\n            print(\"Columns used in analysis:\", intersection)\n            print(\"Column names not identified in data:\", remainder)\n            print('________________________________________________________________')\n    else:\n        raise ValueError(\"List of column names for '{}' empty or in wrong format.\".format(name_variables))\n\n    return intersection\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.pca","title":"<code>pca(data_frame, independent_variables=False, dependent_variables=False, n_comp=2, verbose=False)</code>","text":"<p>Function that performs Principal Component Analysis.</p> <p>Makes use of routine sklearn.decomposition.PCA on the input data and gives the site scores and loadings.</p> <p>Principal component analysis (PCA) is a linear dimensionality reduction technique with applications in exploratory data analysis, visualization and data preprocessing. The data is linearly transformed onto a new coordinate system such that the directions (principal components) capturing the largest variation in the data can be easily identified.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.pca--input","title":"Input","text":"<pre><code>data_frame : pd.dataframe\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : Boolean or list of strings; default False\n    list with column names to select from data_frame\n    being characterized as independent variables (= environment)\ndependent_variables : Boolean or list of strings; default is False\n    list with column names to select from data_frame\n    being characterized as dependent variables (= species)\nn_comp : int, default is 2\n    Number of components to report\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.pca--output","title":"Output","text":"<pre><code>results : Dictionary\n    containing the scores and loadings of the PCA,\n    the percentage of the variation explained by the first principal components,\n    the correlation coefficient between the first two PCs,\n    names of columns (same length as loadings)\n    names of indices (same length as scores)\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/ordination.py</code> <pre><code>def pca(data_frame,\n        independent_variables = False,\n        dependent_variables = False,\n        n_comp = 2,\n        verbose = False,\n        ):\n    \"\"\"Function that performs Principal Component Analysis.\n\n    Makes use of routine sklearn.decomposition.PCA on the input data and gives\n    the site scores and loadings.\n\n    Principal component analysis (PCA) is a linear dimensionality reduction\n    technique with applications in exploratory data analysis, visualization\n    and data preprocessing. The data is linearly transformed onto a new\n    coordinate system such that the directions (principal components) capturing\n    the largest variation in the data can be easily identified.\n\n    Input\n    -----\n        data_frame : pd.dataframe\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : Boolean or list of strings; default False\n            list with column names to select from data_frame\n            being characterized as independent variables (= environment)\n        dependent_variables : Boolean or list of strings; default is False\n            list with column names to select from data_frame\n            being characterized as dependent variables (= species)\n        n_comp : int, default is 2\n            Number of components to report\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n\n    Output\n    ------\n        results : Dictionary\n            containing the scores and loadings of the PCA,\n            the percentage of the variation explained by the first principal components,\n            the correlation coefficient between the first two PCs,\n            names of columns (same length as loadings)\n            names of indices (same length as scores)\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'pca()' on data\")\n        print('==============================================================')\n\n    data,cols= check_data_frame(data_frame)\n\n    if independent_variables is False and dependent_variables is False:\n        data_pca = data\n        names_independent = cols\n        names_dependent = []\n\n    elif independent_variables is not False and dependent_variables is False:\n        names_independent = extract_variables(cols,\n                              independent_variables,\n                              name_variables = 'independent variables'\n                              )\n        names_dependent = []\n        data_pca = data[names_independent]\n    elif independent_variables is False and dependent_variables is not False:\n        names_dependent = extract_variables(cols,\n                              dependent_variables,\n                              name_variables = 'dependent variables'\n                              )\n        names_independent = []\n        data_pca = data[names_dependent]\n\n    else:\n        names_independent = extract_variables(cols,\n                              independent_variables,\n                              name_variables = 'independent variables'\n                              )\n        names_dependent = extract_variables(cols,\n                              dependent_variables,\n                              name_variables = 'dependent variables'\n                              )\n        data_pca = data[names_independent + names_dependent]\n\n    # Checking if the dimensions of the dataframe allow for PCA\n    if data_pca.shape[0] &lt; data_pca.shape[1]:\n        raise ValueError(\"PCA not possible with more variables than samples.\")\n\n    try:\n        # Using scikit.decomposoition.PCA with an amount of components equal\n        # to the amount of variables, then getting the loadings, scores and explained variance ratio.\n        pca = decomposition.PCA(n_components=len(data_pca.columns))\n        pca.fit(data_pca)\n        loadings = pca.components_.T\n        PCAscores = pca.transform(data_pca)\n        variances = pca.explained_variance_ratio_\n    except(ValueError,TypeError):\n        raise TypeError(\"Not all column values are numeric values (or NaN). Consider standardizing data first.\")\n\n    # Taking the first two PC for plotting\n    if dependent_variables is False:\n        loadings_independent = loadings[:, 0:n_comp]\n        loadings_dependent = np.array([[],[]]).T\n    else:\n        loadings_independent = loadings[:-len(names_dependent), 0:n_comp]\n        loadings_dependent = loadings[-len(names_dependent):, 0:n_comp]\n    scores = PCAscores[:, 0:n_comp]\n    percent_explained = np.around(100*variances/np.sum(variances), decimals=2)\n    coef = np.corrcoef(scores[:,0], scores[:,1])[0,1]\n\n    if verbose:\n        print(\"Information about the success of the PCA:\")\n        print('----------------------------------------------------------------')\n        for i in range(len(percent_explained)):\n            print('Principle component {} explains {}% of the total variance.'.format(i,percent_explained[i]))\n        print('\\nThe correlation coefficient between PC1 and PC2 is {:.2e}.'.format(coef))\n        print('----------------------------------------------------------------')\n\n    results = {\"method\": 'pca',\n               \"loadings_dependent\": loadings_dependent,\n               \"loadings_independent\": loadings_independent,\n               \"names_independent\" : names_independent,\n               \"names_dependent\" : names_dependent,\n               \"scores\": scores,\n               \"sample_index\" : list(data_pca.index),\n               \"percent_explained\": percent_explained,\n               \"corr_PC1_PC2\": coef,\n               }\n\n    return results\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.rda","title":"<code>rda(data_frame, independent_variables, dependent_variables, n_comp=2, verbose=False)</code>","text":"<p>Function that performs Redundancy Analysis.</p> <p>Function makes use of skbio.stats.ordination.RDA on the input data and gives the site scores and loadings.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.rda--input","title":"Input","text":"<pre><code>data_frame : pd.dataframe\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nindependent_variables : list of strings\n    list with column names data to be the independent variables (=envirnoment)\ndependent_variables : list of strings\n    list with column names data to be the dependent variables (=species)\nn_comp : int, default is 2\n    number of dimensions to return\nverbose : Boolean, The default is False.\n    Set to True to get messages in the Console about the status of the run code.\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.ordination.rda--output","title":"Output","text":"<pre><code>results : Dictionary\n    * method: name of ordination method (str)\n    * loadings_independent: loadings of independent variables (np.ndarray)\n    * loadings_dependent: loadings of dependent variables (np.ndarray)\n    * names_independent: names of independent varialbes (list of str)\n    * names_dependent: names of dependent varialbes (list of str)\n    * scores: scores (np.ndarray)\n    * sample_index: names of samples (list of str)\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/ordination.py</code> <pre><code>def rda(data_frame,\n        independent_variables,\n        dependent_variables,\n        n_comp = 2,\n        verbose = False,\n        ):\n    \"\"\"Function that performs Redundancy Analysis.\n\n    Function makes use of skbio.stats.ordination.RDA on the input data and gives\n    the site scores and loadings.\n\n    Input\n    -----\n        data_frame : pd.dataframe\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        independent_variables : list of strings\n            list with column names data to be the independent variables (=envirnoment)\n        dependent_variables : list of strings\n            list with column names data to be the dependent variables (=species)\n        n_comp : int, default is 2\n            number of dimensions to return\n        verbose : Boolean, The default is False.\n            Set to True to get messages in the Console about the status of the run code.\n\n    Output\n    ------\n        results : Dictionary\n            * method: name of ordination method (str)\n            * loadings_independent: loadings of independent variables (np.ndarray)\n            * loadings_dependent: loadings of dependent variables (np.ndarray)\n            * names_independent: names of independent varialbes (list of str)\n            * names_dependent: names of dependent varialbes (list of str)\n            * scores: scores (np.ndarray)\n            * sample_index: names of samples (list of str)\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'rda()' on data\")\n        print('==============================================================')\n\n    results = constrained_ordination(data_frame,\n                           independent_variables,\n                           dependent_variables,\n                           method = 'rda',\n                           n_comp = n_comp,\n                           )\n    return results\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression","title":"<code>stable_isotope_regression</code>","text":"<p>Routines for performing linear regression on isotope data.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Keeling_regression","title":"<code>Keeling_regression(concentration, delta_mix=None, relative_abundance=None, validate_indices=True, verbose=False, **kwargs)</code>","text":"<p>Performing a linear regression linked to the Keeling plot.</p> <p>A Keeling fit/plot is an approach to identify the isotopic composition of a contaminating source from measured concentrations and isotopic composition (delta) of a target species in the mix of the source and a pool.</p> <p>It is based on the linear relationship of the given quantities (concentration) and delta-values (or alternatively the relative abundance x) which are measured over time or across a spatial interval according to</p> <pre><code>delta_mix = delta_source + m * 1/c_mix\n</code></pre> <p>where m is the slope relating the isotopic quantities of the pool (which mixes with the sourse) by m = (delta_pool + delta_source)*c_pool.</p> <p>The analysis is based on a linear regression of the inverse concentration data against the delta (or x)-values. The parameter of interest, the delta (or relative_abundance, respectively) of the source quantity is the intercept of linear fit with the y-axis, or in other words, the absolute value of the linear fit function.</p> <p>A plot of the results with data and linear trendline can be generate with the method Keeling_plot() [in the module visualize].</p> <p>Note that the approach is only applicable if     (i)  the isotopic composition of the unknown source is constant     (ii) the concentration and isotopic composition of the target compound         is constant (over time or across space)         (i.e. in absence of contamination from the unknown source)</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Keeling_regression--input","title":"Input","text":"<pre><code>concentration : np.array, pd.dataframe\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta_mix : np.array, pd.dataframe (same length as c_mix), default None\n    relative isotope ratio (delta-value) of target substance\nrelative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n    if not None it replaces delta_mix in the inverse estimation and plotting\n    relative abundance of target substance\nvalidate_indices: boolean, default True\n    flag to run index validation (i.e. removal of nan and infinity values)\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n**kwargs : dict\n    keywordarguments dictionary, e.g. for passing forward keywords to\n    valid_indices()\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Keeling_regression--returns","title":"Returns","text":"<pre><code>results : dict\n    results of fitting, including:\n        * coefficients : array/list of lenght 2, where coefficients[0]\n            is the slope of the linear fit and coefficient[1] is the\n            intercept of linear fit with y-axis, reflecting delta\n            (or relative_abundance, respectively) of the source quantity\n        * delta_C: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n        * delta_H: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def Keeling_regression(concentration,\n                       delta_mix = None,\n                       relative_abundance = None,\n                       validate_indices = True,\n                       verbose = False,\n                       **kwargs,\n                       ):\n    \"\"\"Performing a linear regression linked to the Keeling plot.\n\n    A Keeling fit/plot is an approach to identify the isotopic composition of a\n    contaminating source from measured concentrations and isotopic composition\n    (delta) of a target species in the mix of the source and a pool.\n\n    It is based on the linear relationship of the given quantities (concentration)\n    and delta-values (or alternatively the relative abundance x) which are measured\n    over time or across a spatial interval according to\n\n        delta_mix = delta_source + m * 1/c_mix\n\n    where m is the slope relating the isotopic quantities of the pool (which mixes\n    with the sourse) by m = (delta_pool + delta_source)*c_pool.\n\n    The analysis is based on a linear regression of the inverse concentration\n    data against the delta (or x)-values. The parameter of interest, the delta\n    (or relative_abundance, respectively) of the source quantity is the\n    intercept of linear fit with the y-axis, or in other words, the absolute\n    value of the linear fit function.\n\n    A plot of the results with data and linear trendline can be generate with the\n    method Keeling_plot() [in the module visualize].\n\n    Note that the approach is only applicable if\n        (i)  the isotopic composition of the unknown source is constant\n        (ii) the concentration and isotopic composition of the target compound\n            is constant (over time or across space)\n            (i.e. in absence of contamination from the unknown source)\n\n    Input\n    -----\n        concentration : np.array, pd.dataframe\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta_mix : np.array, pd.dataframe (same length as c_mix), default None\n            relative isotope ratio (delta-value) of target substance\n        relative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n            if not None it replaces delta_mix in the inverse estimation and plotting\n            relative abundance of target substance\n        validate_indices: boolean, default True\n            flag to run index validation (i.e. removal of nan and infinity values)\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n        **kwargs : dict\n            keywordarguments dictionary, e.g. for passing forward keywords to\n            valid_indices()\n\n    Returns\n    -------\n        results : dict\n            results of fitting, including:\n                * coefficients : array/list of lenght 2, where coefficients[0]\n                    is the slope of the linear fit and coefficient[1] is the\n                    intercept of linear fit with y-axis, reflecting delta\n                    (or relative_abundance, respectively) of the source quantity\n                * delta_C: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n                * delta_H: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'Keeling_regression()' on data\")\n        print('==============================================================')\n\n    if delta_mix is not None:\n        y = delta_mix\n        text = 'delta'\n    elif relative_abundance is not None:\n        y = relative_abundance\n        text = 'relative abundance'\n    else:\n        raise ValueError(\"One of the quantities 'delta_mix' or 'relative_abundance' must be provided\")\n\n    ### ---------------------------------------------------------------------------\n    ### check length of data arrays and remove non-valid values (NaN, inf &amp; zero)\n\n    if validate_indices:\n        data1, data2 = valid_indices(concentration,\n                                 y,\n                                 remove_nan = True,\n                                 remove_infinity = True,\n                                 remove_zero = True,\n                                 **kwargs,\n                                 )\n    else:\n        data1, data2 = concentration,y\n\n    ### ---------------------------------------------------------------------------\n    ### perform linear regression\n\n    coefficients = np.polyfit(1./data1, data2, 1)\n\n    if verbose:\n        print(\"The {} of the source quantity, being the intercept\".format(text))\n        print(\"of the linear fit, is identified with {:.2f}\".format(coefficients[1]))\n        print('______________________________________________________________')\n\n    results = dict(\n        concentration = data1,\n        delta = data2,\n        coefficients = coefficients,\n        )\n\n    return results\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Lambda_regression","title":"<code>Lambda_regression(delta_C, delta_H, validate_indices=True, verbose=False, **kwargs)</code>","text":"<p>Performing linear regression to achieve Lambda value.</p> <p>The Lambda values relates the \u03b413C versus \u03b42H signatures of a chemical compound. Relative changes in the ratio can indicate the occurrence of specific enzymatic degradation reactions.</p> <p>The analysis is based on a linear regression of the hydrogen versus carbon isotope signatures. The parameter of interest, the Lambda values is the slope of the the linear trend line.</p> <p>A plot of the results with data and linear trendline can be generate with the method Lambda_plot() [in the module visualize].</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Lambda_regression--input","title":"Input","text":"<pre><code>delta_C : np.array, pd.series\n    relative isotope ratio (delta-value) of carbon of target molecule\ndelta_H : np.array, pd.series (same length as delta_C)\n    relative isotope ratio (delta-value) of hydrogen of target molecule\nvalidate_indices: boolean, default True\n    flag to run index validation (i.e. removal of nan and infinity values)\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n**kwargs : dict\n    keywordarguments dictionary, e.g. for passing forward keywords to\n    valid_indices()\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Lambda_regression--returns","title":"Returns","text":"<pre><code>results : dict\n    results of fitting, including:\n        * coefficients : array/list of lenght 2, where coefficients[0]\n            is the slope of the linear fit, reflecting the lambda values\n            and coefficient[1] is the absolute value of the linear function\n        * delta_C: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n        * delta_H: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def Lambda_regression(delta_C,\n                      delta_H,\n                      validate_indices = True,\n                      verbose = False,\n                      **kwargs,\n                      ):\n    \"\"\"Performing linear regression to achieve Lambda value.\n\n    The Lambda values relates the \u03b413C versus \u03b42H signatures of a chemical\n    compound. Relative changes in the ratio can indicate the occurrence of\n    specific enzymatic degradation reactions.\n\n    The analysis is based on a linear regression of the hydrogen versus\n    carbon isotope signatures. The parameter of interest, the Lambda values\n    is the slope of the the linear trend line.\n\n    A plot of the results with data and linear trendline can be generate with the\n    method Lambda_plot() [in the module visualize].\n\n    Input\n    -----\n        delta_C : np.array, pd.series\n            relative isotope ratio (delta-value) of carbon of target molecule\n        delta_H : np.array, pd.series (same length as delta_C)\n            relative isotope ratio (delta-value) of hydrogen of target molecule\n        validate_indices: boolean, default True\n            flag to run index validation (i.e. removal of nan and infinity values)\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n        **kwargs : dict\n            keywordarguments dictionary, e.g. for passing forward keywords to\n            valid_indices()\n\n    Returns\n    -------\n        results : dict\n            results of fitting, including:\n                * coefficients : array/list of lenght 2, where coefficients[0]\n                    is the slope of the linear fit, reflecting the lambda values\n                    and coefficient[1] is the absolute value of the linear function\n                * delta_C: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n                * delta_H: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n    \"\"\"\n    ### ---------------------------------------------------------------------------\n    ### check length of data arrays and remove non-valid values (NaN, inf &amp; zero)\n\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'Lambda_regression()' on data\")\n        print('==============================================================')\n\n    if validate_indices:\n        data1, data2 = valid_indices(delta_C,\n                                     delta_H,\n                                     remove_nan = True,\n                                     remove_infinity = True,\n                                     remove_zero=True,\n                                     )\n    else:\n        data1, data2 = delta_C,delta_H\n\n    ### ---------------------------------------------------------------------------\n    ### perform linear regression\n\n    coefficients = np.polyfit(data1, data2, 1)\n\n    if verbose:\n        print(\"Lambda value, being the slope of the linear fit is \\n identified with {:.2f}\".format(coefficients[0]))\n        print('______________________________________________________________')\n\n    results = dict(\n        delta_C = data1,\n        delta_H = data2,\n        coefficients = coefficients,\n        )\n\n    return results\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Rayleigh_fractionation","title":"<code>Rayleigh_fractionation(concentration, delta, validate_indices=True, verbose=False, **kwargs)</code>","text":"<p>Performing Rayleigh fractionation analysis.</p> <p>Rayleigh fractionation is a common application to characterize the removal of a substance from a finite pool using stable isotopes. It is based on the change in the isotopic composition of the pool due to different kinetics of the change in lighter and heavier isotopes.</p> <p>We follow the most simple approach assuming that the substance removal follows first-order kinetics, where the rate coefficients for the lighter and heavier isotopes of the substance differ due to kinetic isotope fractionation effects. The isotopic composition of the remaining substance in the pool will change over time, leading to the so-called Rayleigh fractionation.</p> <p>The analysis is based on a linear regression of the log-transformed concentration data against the delta-values. The parameter of interest, the kinetic fractionation factor (epsilon or alpha -1) of the removal process is the slope of the the linear trend line.</p> <p>A plot of the results with data and linear trendline can be generate with the method Rayleigh_fractionation_plot() [in the module visualize].</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Rayleigh_fractionation--input","title":"Input","text":"<pre><code>concentration : np.array, pd.dataframe\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta : np.array, pd.dataframe (same length as concentration)\n    relative isotope ratio (delta-value) of target substance\nvalidate_indices: boolean, default True\n    flag to run index validation (i.e. removal of nan and infinity values)\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n**kwargs : dict\n    keywordarguments dictionary, e.g. for passing forward keywords to\n    valid_indices()\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.Rayleigh_fractionation--returns","title":"Returns","text":"<pre><code>results : dict\n    results of fitting, including:\n        * coefficients : array/list of lenght 2, where coefficients[0]\n            is the slope of the linear fit, reflecting the kinetic\n            fractionation factor (epsilon or alpha -1) of the removal process\n            and coefficient[1] is the absolute value of the linear function\n        * delta_C: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n        * delta_H: np.array with isotope used for fitting - all samples\n            where non-zero values are available for delta_C and delta_H\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def Rayleigh_fractionation(concentration,\n                           delta,\n                           validate_indices = True,\n                           verbose = False,\n                           **kwargs,\n                           ):\n    \"\"\"Performing Rayleigh fractionation analysis.\n\n    Rayleigh fractionation is a common application to characterize the removal\n    of a substance from a finite pool using stable isotopes. It is based on the\n    change in the isotopic composition of the pool due to different kinetics of\n    the change in lighter and heavier isotopes.\n\n    We follow the most simple approach assuming that the substance removal follows\n    first-order kinetics, where the rate coefficients for the lighter and heavier\n    isotopes of the substance differ due to kinetic isotope fractionation effects.\n    The isotopic composition of the remaining substance in the pool will change\n    over time, leading to the so-called Rayleigh fractionation.\n\n    The analysis is based on a linear regression of the log-transformed concentration\n    data against the delta-values. The parameter of interest, the kinetic\n    fractionation factor (epsilon or alpha -1) of the removal process is the slope\n    of the the linear trend line.\n\n    A plot of the results with data and linear trendline can be generate with the\n    method Rayleigh_fractionation_plot() [in the module visualize].\n\n    Input\n    -----\n        concentration : np.array, pd.dataframe\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta : np.array, pd.dataframe (same length as concentration)\n            relative isotope ratio (delta-value) of target substance\n        validate_indices: boolean, default True\n            flag to run index validation (i.e. removal of nan and infinity values)\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n        **kwargs : dict\n            keywordarguments dictionary, e.g. for passing forward keywords to\n            valid_indices()\n\n    Returns\n    -------\n        results : dict\n            results of fitting, including:\n                * coefficients : array/list of lenght 2, where coefficients[0]\n                    is the slope of the linear fit, reflecting the kinetic\n                    fractionation factor (epsilon or alpha -1) of the removal process\n                    and coefficient[1] is the absolute value of the linear function\n                * delta_C: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n                * delta_H: np.array with isotope used for fitting - all samples\n                    where non-zero values are available for delta_C and delta_H\n    \"\"\"\n    ### ---------------------------------------------------------------------------\n    ### check length of data arrays and remove non-valid values (NaN, inf &amp; zero)\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'Rayleigh_fractionation()' on data\")\n        print('==============================================================')\n\n    if validate_indices:\n        data1, data2 = valid_indices(concentration,\n                                 delta,\n                                 remove_nan = True,\n                                 remove_infinity = True,\n                                 remove_zero = True,\n                                 **kwargs,\n                                 )\n    else:\n        data1, data2 = concentration,delta\n\n    ### ---------------------------------------------------------------------------\n    ### perform linear regression\n    if np.any(data1&lt;=0):\n        raise ValueError(\"Concentration data provided is negative, but has to be positive.\")\n\n    coefficients = np.polyfit(np.log(data1), data2, 1)\n\n    if verbose:\n        print(\"The kinetic fractionation factor ('epsilon' or 'alpha-1') of\")\n        print(\"the removal process, being the slope of the linear fit, is \")\n        print(\"identified with {:.2f}\".format(coefficients[0]))\n        print('______________________________________________________________')\n\n    results = dict(\n        concentration = data1,\n        delta = data2,\n        coefficients = coefficients,\n        )\n\n    return results\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.extract_isotope_data","title":"<code>extract_isotope_data(df, molecule, name_13C='delta_13C', name_2H='delta_2H')</code>","text":"<p>Extracts isotope data from standardised input-dataframe.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.extract_isotope_data--parameters","title":"Parameters","text":"<p>df : pd.dataframe     numeric (observational) data molecule : str     name of contaminant molecule to extract isotope data for name_13C : str, default \u2018delta_13C\u2019 (standard name)     name of C13 isotope to extract data for name_2H : str, default \u2018delta_2H\u2019 (standard name)     name of deuterium isotope to extract data for</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.extract_isotope_data--returns","title":"Returns","text":"<p>C_data : np.array     numeric isotope data H_data : np.array     numeric isotope data</p> Source code in <code>mibiscreen/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def extract_isotope_data(df,\n                         molecule,\n                         name_13C = 'delta_13C',\n                         name_2H = 'delta_2H',\n                         ):\n    \"\"\"Extracts isotope data from standardised input-dataframe.\n\n    Parameters\n    ----------\n    df : pd.dataframe\n        numeric (observational) data\n    molecule : str\n        name of contaminant molecule to extract isotope data for\n    name_13C : str, default 'delta_13C' (standard name)\n        name of C13 isotope to extract data for\n    name_2H : str, default 'delta_2H' (standard name)\n        name of deuterium isotope to extract data for\n\n    Returns\n    -------\n    C_data : np.array\n        numeric isotope data\n    H_data : np.array\n        numeric isotope data\n\n    \"\"\"\n    molecule_standard = names_contaminants.get(molecule.lower(), False)\n    isotope_13C = names_isotopes.get(name_13C.lower(), False)\n    isotope_2H = names_isotopes.get(name_2H.lower(), False)\n\n    if molecule_standard is False:\n        raise ValueError(\"Contaminant (name) unknown: {}\".format(molecule))\n    if isotope_13C is False:\n        raise ValueError(\"Isotope (name) unknown: {}\".format(name_13C))\n    if isotope_2H is False:\n        raise ValueError(\"Isotope (name) unknown: {}\".format(name_2H))\n\n    name_C = '{}-{}'.format(isotope_13C,molecule_standard)\n    name_H = '{}-{}'.format(isotope_2H,molecule_standard)\n\n    if name_C not in df.columns.to_list():\n        raise ValueError(\"No isotope data available for : {}\".format(name_C))\n    if name_H not in df.columns.to_list():\n        raise ValueError(\"No isotope data available for : {}\".format(name_H))\n\n    C_data = df[name_C].values\n    H_data = df[name_H].values\n\n    return C_data, H_data\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.valid_indices","title":"<code>valid_indices(data1, data2, remove_nan=True, remove_infinity=True, remove_zero=False, **kwargs)</code>","text":"<p>Identifies valid indices in two equaly long arrays and compresses both.</p> <p>Optional numerical to remove from array are: nan, infinity and zero values.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.valid_indices--parameters","title":"Parameters","text":"<p>data1 : np.array or pd.series     numeric data data2 : np.array or pd.series (same len/shape as data1)     numeric data remove_nan : boolean, default True     flag to remove nan-values remove_infinity : boolean, default True     flag to remove infinity values remove_zero : boolean, default False     flag to remove zero values **kwargs : dict     keywordarguments dictionary</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.stable_isotope_regression.valid_indices--returns","title":"Returns","text":"<p>data1 : np.array or pd.series     numeric data of reduced length where only data at valid indices is in data2 : np.array or pd.series     numeric data of reduced length where only data at valid indices is in</p> Source code in <code>mibiscreen/analysis/reduction/stable_isotope_regression.py</code> <pre><code>def valid_indices(data1,\n                  data2,\n                  remove_nan = True,\n                  remove_infinity = True,\n                  remove_zero = False,\n                  **kwargs,\n                  ):\n    \"\"\"Identifies valid indices in two equaly long arrays and compresses both.\n\n    Optional numerical to remove from array are: nan, infinity and zero values.\n\n    Parameters\n    ----------\n    data1 : np.array or pd.series\n        numeric data\n    data2 : np.array or pd.series (same len/shape as data1)\n        numeric data\n    remove_nan : boolean, default True\n        flag to remove nan-values\n    remove_infinity : boolean, default True\n        flag to remove infinity values\n    remove_zero : boolean, default False\n        flag to remove zero values\n    **kwargs : dict\n        keywordarguments dictionary\n\n    Returns\n    -------\n    data1 : np.array or pd.series\n        numeric data of reduced length where only data at valid indices is in\n    data2 : np.array or pd.series\n        numeric data of reduced length where only data at valid indices is in\n\n    \"\"\"\n    if data1.shape != data2.shape:\n        raise ValueError(\"Shape of provided data must be identical.\")\n\n    valid_indices = np.full(data1.shape, True, dtype=bool)\n\n    if remove_nan:\n        valid_indices *= ~np.isnan(data1) &amp; ~np.isinf(data1)\n    if remove_infinity:\n        valid_indices *= ~np.isnan(data2) &amp; ~np.isinf(data2)\n    if remove_zero:\n        valid_indices *= (data1 != 0) &amp; (data2 != 0)\n\n    return data1[valid_indices],data2[valid_indices]\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.transformation","title":"<code>transformation</code>","text":"<p>Routines for performing ordination statistics on sample data.</p> <p>@author: Alraune Zech, Jorrit Bakker</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.transformation.filter_values","title":"<code>filter_values(data_frame, replace_NaN='remove', drop_rows=[], inplace=False, verbose=False)</code>","text":"<p>Filtering values of dataframes for ordination to assure all are numeric.</p> <p>Ordination methods require all cells to be filled. This method checks the provided data frame if values are missing/NaN or not numeric and handles missing/NaN values accordingly.</p> <p>It then removes select rows and mutates the cells containing NULL values based on the input parameters.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.transformation.filter_values--input","title":"Input","text":"<pre><code>data_frame : pd.dataframe\n    Tabular data containing variables to be evaluated with standard\n    column names and rows of sample data.\nreplace_NaN : string or float, default \"remove\"\n    Keyword specifying how to handle missing/NaN/non-numeric values, options:\n        - remove: remove rows with missing values\n        - zero: replace values with 0.0\n        - average: replace the missing values with the average of the variable\n                    (using all other available samples)\n        - median: replace the missing values with the median of the variable\n                                (using all other available samples)\n        - float-value: replace all empty cells with that numeric value\ndrop_rows : List, default [] (empty list)\n    List of rows that should be removed from dataframe.\ninplace: bool, default True\n    If False, return a copy. Otherwise, do operation in place.\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.transformation.filter_values--output","title":"Output","text":"<pre><code>data_filtered : pd.dataframe\n    Tabular data containing filtered data.\n</code></pre> Source code in <code>mibiscreen/analysis/reduction/transformation.py</code> <pre><code>def filter_values(data_frame,\n                  replace_NaN = 'remove',\n                  drop_rows = [],\n                  inplace = False,\n                  verbose = False):\n    \"\"\"Filtering values of dataframes for ordination to assure all are numeric.\n\n    Ordination methods require all cells to be filled. This method checks the\n    provided data frame if values are missing/NaN or not numeric and handles\n    missing/NaN values accordingly.\n\n    It then removes select rows and mutates the cells containing NULL values based\n    on the input parameters.\n\n    Input\n    -----\n        data_frame : pd.dataframe\n            Tabular data containing variables to be evaluated with standard\n            column names and rows of sample data.\n        replace_NaN : string or float, default \"remove\"\n            Keyword specifying how to handle missing/NaN/non-numeric values, options:\n                - remove: remove rows with missing values\n                - zero: replace values with 0.0\n                - average: replace the missing values with the average of the variable\n                            (using all other available samples)\n                - median: replace the missing values with the median of the variable\n                                        (using all other available samples)\n                - float-value: replace all empty cells with that numeric value\n        drop_rows : List, default [] (empty list)\n            List of rows that should be removed from dataframe.\n        inplace: bool, default True\n            If False, return a copy. Otherwise, do operation in place.\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n\n    Output\n    ------\n        data_filtered : pd.dataframe\n            Tabular data containing filtered data.\n    \"\"\"\n    data,cols= check_data_frame(data_frame,inplace = inplace)\n\n    if verbose:\n        print(\"==============================================================================\")\n        print('Perform filtering of values since ordination requires all values to be numeric.')\n\n    if len(drop_rows)&gt;0:\n        data.drop(drop_rows, inplace = True)\n        if verbose:\n            print('The samples of rows {} have been removed'.format(drop_rows))\n\n    # Identifying which rows and columns contain any amount of NULL cells and putting them in a list.\n    NaN_rows = data[data.isna().any(axis=1)].index.tolist()\n    NaN_cols = data.columns[data.isna().any()].tolist()\n\n    # If there are any rows containing NULL cells, the NULL values will be filtered\n    if len(NaN_rows)&gt;0:\n        if replace_NaN == 'remove':\n            data.drop(NaN_rows, inplace = True)\n            text = 'The sample row(s) have been removed since they contain NaN values: {}'.format(NaN_rows)\n        elif replace_NaN == 'zero':\n            set_NaN = 0.0\n            data.fillna(set_NaN, inplace = True)\n            text = 'The values of the empty cells have been set to zero (0.0)'\n        elif isinstance(replace_NaN, (float, int)):\n            set_NaN = float(replace_NaN)\n            data.fillna(set_NaN, inplace = True)\n            text = 'The values of the empty cells have been set to the value of {}'.format(set_NaN)\n        elif replace_NaN == \"average\":\n            for var in NaN_cols:\n                data[var] = data[var].fillna(data[var].mean(skipna = True))\n            text = 'The values of the empty cells have been replaced by the average of\\\n                  the corresponding variables (using all other available samples).'\n        elif replace_NaN == \"median\":\n            for var in NaN_cols:\n                data[var] = data[var].fillna(data[var].median(skipna = True))\n            text = 'The values of the empty cells have been replaced by the median of\\\n                  the corresponding variables (using all other available samples).'\n        else:\n            raise ValueError(\"Value of 'replace_NaN' unknown: {}\".format(replace_NaN))\n    else:\n        text = 'No data to be filtered out.'\n\n    if verbose:\n        print(text)\n\n    return data\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.transformation.transform_values","title":"<code>transform_values(data_frame, name_list='all', how='log_scale', log_scale_A=1, log_scale_B=1, inplace=False, verbose=False)</code>","text":"<p>Extracting data from dataframe for specified variables.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements\nname_list: string or list of strings, default 'all'\n    list of quantities (column names) to perfrom transformation on\nhow: string, default 'standardize'\n    Type of transformation:\n        * standardize\n        * log_scale\n        * center\nlog_scale_A : Integer or float, default 1\n    Log transformation parameter A: log10(Ax+B).\nlog_scale_B : Integer or float, default 1\n    Log transformation parameter B: log10(Ax+B).\ninplace: bool, default True\n    If False, return a copy. Otherwise, do operation in place and return None.\nverbose : Boolean, The default is False.\n   Set to True to get messages in the Console about the status of the run code.\n</code></pre> <pre><code>data: pd.DataFrame\n    dataframe with the measurements\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.transformation.transform_values--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.reduction.transformation.transform_values--example","title":"Example:","text":"<p>To be added.</p> Source code in <code>mibiscreen/analysis/reduction/transformation.py</code> <pre><code>def transform_values(data_frame,\n                     name_list = 'all',\n                     how = 'log_scale',\n                     log_scale_A = 1,\n                     log_scale_B = 1,\n                     inplace = False,\n                     verbose = False,\n                     ):\n    \"\"\"Extracting data from dataframe for specified variables.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements\n        name_list: string or list of strings, default 'all'\n            list of quantities (column names) to perfrom transformation on\n        how: string, default 'standardize'\n            Type of transformation:\n                * standardize\n                * log_scale\n                * center\n        log_scale_A : Integer or float, default 1\n            Log transformation parameter A: log10(Ax+B).\n        log_scale_B : Integer or float, default 1\n            Log transformation parameter B: log10(Ax+B).\n        inplace: bool, default True\n            If False, return a copy. Otherwise, do operation in place and return None.\n        verbose : Boolean, The default is False.\n           Set to True to get messages in the Console about the status of the run code.\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            dataframe with the measurements\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    To be added.\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'transform_values()' on data\")\n        print('==============================================================')\n\n    data,cols= check_data_frame(data_frame,inplace = inplace)\n    quantities, _ = determine_quantities(cols,\n                                      name_list = name_list,\n                                      verbose = verbose)\n\n    for quantity in quantities:\n        if how == 'log_scale':\n            data[quantity] = np.log10(log_scale_A * data[quantity] + log_scale_B)\n        elif how == 'center':\n            data[quantity] =  data[quantity]-data[quantity].mean()\n        elif how == 'standardize':\n            data[quantity] = zscore(data[quantity].values)\n        else:\n            raise ValueError(\"Value of 'how' unknown: {}\".format(how))\n\n    return data\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample","title":"<code>sample</code>","text":"<p>mibiscreen module for data analysis performed on each sample.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations","title":"<code>concentrations</code>","text":"<p>Routines for calculating total concentrations and counts for samples.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.thresholds_for_intervention","title":"<code>thresholds_for_intervention(data_frame, contaminant_group='BTEXIIN', include=False, verbose=False)</code>","text":"<p>Function to evalute intervention threshold exceedance.</p> <pre><code>Determines which contaminants exceed concentration thresholds set by\nthe Dutch government for intervention.\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.thresholds_for_intervention--input","title":"Input","text":"<pre><code>data_frame: pd.DataFrame\n    Contaminant contentrations in [ug/l], i.e. microgram per liter\ncontaminant_group: str\n    Short name for group of contaminants to use\n    default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\ninclude: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean, default False\n    verbose flag\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.thresholds_for_intervention--output","title":"Output","text":"<pre><code>intervention: pd.DataFrame\n    DataFrame of similar format as input data with well specification and\n    three columns on intervention threshold exceedance analysis:\n        - traffic light if well requires intervention\n        - number of contaminants exceeding the intervention value\n        - list of contaminants above the threshold of intervention\n</code></pre> Source code in <code>mibiscreen/analysis/sample/concentrations.py</code> <pre><code>def thresholds_for_intervention(\n        data_frame,\n        contaminant_group = \"BTEXIIN\",\n        include = False,\n        verbose = False,\n        ):\n    \"\"\"Function to evalute intervention threshold exceedance.\n\n        Determines which contaminants exceed concentration thresholds set by\n        the Dutch government for intervention.\n\n    Input\n    -----\n        data_frame: pd.DataFrame\n            Contaminant contentrations in [ug/l], i.e. microgram per liter\n        contaminant_group: str\n            Short name for group of contaminants to use\n            default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n        include: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean, default False\n            verbose flag\n\n    Output\n    ------\n        intervention: pd.DataFrame\n            DataFrame of similar format as input data with well specification and\n            three columns on intervention threshold exceedance analysis:\n                - traffic light if well requires intervention\n                - number of contaminants exceeding the intervention value\n                - list of contaminants above the threshold of intervention\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'thresholds_for_intervention()' on data\")\n        print('==============================================================')\n\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = include)\n\n    ### sorting out which columns in data to evaluate\n    quantities, _ = determine_quantities(cols,\n                                      name_list = contaminant_group,\n                                      verbose = verbose)\n\n    if include:\n        intervention = data\n    else:\n        intervention= extract_settings(data)\n\n    nr_samples = data.shape[0] # number of samples\n    traffic_nr = np.zeros(nr_samples,dtype=int)\n    traffic_list = [[] for _ in range(nr_samples)]\n\n    try:\n        for cont in quantities:\n            th_value = properties[cont]['thresholds_for_intervention_NL']\n            traffic_nr += (data[cont].values &gt; th_value)\n            for i in range(nr_samples):\n                if data[cont].values[i] &gt; th_value:\n                    traffic_list[i].append(cont)\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    traffic_light = np.where(traffic_nr&gt;0,\"red\",\"green\")\n    traffic_light[np.isnan(traffic_nr)] = 'y'\n    intervention[names.name_intervention_traffic] = traffic_light\n    intervention[names.name_intervention_number] = traffic_nr\n    intervention[names.name_intervention_contaminants] = traffic_list\n\n    if verbose:\n        print(\"Evaluation of contaminant concentrations exceeding intervention values for {}:\".format(\n            contaminant_group))\n        print('------------------------------------------------------------------------------------')\n        print(\"Red light: Intervention values exceeded for {} out of {} locations\".format(\n            np.sum(traffic_nr &gt;0),data.shape[0]))\n        print(\"green light: Concentrations below intervention values at {} out of {} locations\".format(\n            np.sum(traffic_nr == 0),data.shape[0]))\n        print(\"Yellow light: No decision possible at {} out of {} locations\".format(\n            np.sum(np.isnan(traffic_nr)),data.shape[0]))\n        print('________________________________________________________________')\n\n    return intervention\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_concentration","title":"<code>total_concentration(data_frame, name_list='all', name_column=False, verbose=False, include=False, **kwargs)</code>","text":"<p>Calculate total concentration of given list of quantities.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_concentration--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Contaminant concentrations in [ug/l], i.e. microgram per liter\nname_list: str or list, dafault is 'all'\n    either short name for group of quantities to use, such as:\n            - 'all' (all qunatities given in data frame except settings)\n            - 'BTEX' (for contaminant group: benzene, toluene, ethylbenzene, xylene)\n            - 'BTEXIIN' (for contaminant group: benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\n    or list of strings with names of quantities to use\nname_column: str or False, default is 'False'\n    optional name of column\nverbose: Boolean\n    verbose flag (default False)\ninclude: bool, default False\n    whether to include calculated values to DataFrame\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_concentration--output","title":"Output","text":"<pre><code>tot_conc: pd.Series\n    Total concentration of contaminants in [ug/l]\n</code></pre> Source code in <code>mibiscreen/analysis/sample/concentrations.py</code> <pre><code>def total_concentration(\n        data_frame,\n        name_list = \"all\",\n        name_column = False,\n        verbose = False,\n        include = False,\n        **kwargs,\n        ):\n    \"\"\"Calculate total concentration of given list of quantities.\n\n    Input\n    -----\n        data: pd.DataFrame\n            Contaminant concentrations in [ug/l], i.e. microgram per liter\n        name_list: str or list, dafault is 'all'\n            either short name for group of quantities to use, such as:\n                    - 'all' (all qunatities given in data frame except settings)\n                    - 'BTEX' (for contaminant group: benzene, toluene, ethylbenzene, xylene)\n                    - 'BTEXIIN' (for contaminant group: benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n            or list of strings with names of quantities to use\n        name_column: str or False, default is 'False'\n            optional name of column\n        verbose: Boolean\n            verbose flag (default False)\n        include: bool, default False\n            whether to include calculated values to DataFrame\n\n\n    Output\n    ------\n        tot_conc: pd.Series\n            Total concentration of contaminants in [ug/l]\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'total_concentration()' on data\")\n        print('==============================================================')\n\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = include)\n\n    ### sorting out which columns in data to use for summation of concentrations\n    quantities, _ = determine_quantities(cols,name_list = name_list, verbose = verbose)\n\n    ### actually performing summation\n    # try:\n    tot_conc = data[quantities].sum(axis = 1)\n    # except TypeError:\n    #     raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    if name_column is False:\n        if isinstance(name_list, str):\n            name_column = 'total concentration {}'.format(name_list)\n        elif isinstance(name_list, list):\n            name_column = 'total concentration selection'\n    else:\n        if not isinstance(name_column, str):\n            raise ValueError(\"Keyword 'name_column' needs to be a string or False.\")\n\n    tot_conc.rename(name_column,inplace = True)\n    if verbose:\n        print('________________________________________________________________')\n        print(\"{} in [ug/l] is:\\n{}\".format(name_column,tot_conc))\n        print('--------------------------------------------------')\n\n    ### additing series to data frame\n    if include:\n        data[name_column] = tot_conc\n\n    return tot_conc\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_contaminant_concentration","title":"<code>total_contaminant_concentration(data_frame, contaminant_group='BTEXIIN', include=False, verbose=False)</code>","text":"<p>Function to calculate total concentration of contaminants.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_contaminant_concentration--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Contaminant contentrations in [ug/l], i.e. microgram per liter\ncontaminant_group: str\n    Short name for group of contaminants to use\n    default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\ninclude: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_contaminant_concentration--output","title":"Output","text":"<pre><code>tot_conc: pd.Series\n    Total concentration of contaminants in [ug/l]\n</code></pre> Source code in <code>mibiscreen/analysis/sample/concentrations.py</code> <pre><code>def total_contaminant_concentration(\n        data_frame,\n        contaminant_group = \"BTEXIIN\",\n        include = False,\n        verbose = False,\n        ):\n    \"\"\"Function to calculate total concentration of contaminants.\n\n    Input\n    -----\n        data: pd.DataFrame\n            Contaminant contentrations in [ug/l], i.e. microgram per liter\n        contaminant_group: str\n            Short name for group of contaminants to use\n            default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n        include: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        tot_conc: pd.Series\n            Total concentration of contaminants in [ug/l]\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'total_contaminant_concentration()' on data\")\n        print('==============================================================')\n\n    tot_conc = total_concentration(\n        data_frame,\n        name_list = contaminant_group,\n        name_column = names.name_total_contaminants,\n        verbose = verbose,\n        include = include,\n        )\n\n    return tot_conc\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_count","title":"<code>total_count(data_frame, name_list='all', threshold=0.0, verbose=False, include=False, **kwargs)</code>","text":"<p>Calculate total number of quantities with concentration exceeding threshold value.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_count--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Contaminant concentrations in [ug/l], i.e. microgram per liter\nname_ist: str or list, dafault is 'all'\n    either short name for group of quantities to use, such as:\n            - 'all' (all qunatities given in data frame except settings)\n            - 'BTEX' (for benzene, toluene, ethylbenzene, xylene)\n            - 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\n    or list of strings with names of quantities to use\nthreshold: float, default 0\n    threshold concentration value in [ug/l] to test on exceedence\nverbose: Boolean\n    verbose flag (default False)\ninclude: bool, default False\n    whether to include calculated values to DataFrame\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.concentrations.total_count--output","title":"Output","text":"<pre><code>tot_count: pd.Series\n    Total number of quantities with concentration exceeding threshold value\n</code></pre> Source code in <code>mibiscreen/analysis/sample/concentrations.py</code> <pre><code>def total_count(\n        data_frame,\n        name_list = \"all\",\n        threshold = 0.,\n        verbose = False,\n        include = False,\n        **kwargs,\n        ):\n    \"\"\"Calculate total number of quantities with concentration exceeding threshold value.\n\n    Input\n    -----\n        data: pd.DataFrame\n            Contaminant concentrations in [ug/l], i.e. microgram per liter\n        name_ist: str or list, dafault is 'all'\n            either short name for group of quantities to use, such as:\n                    - 'all' (all qunatities given in data frame except settings)\n                    - 'BTEX' (for benzene, toluene, ethylbenzene, xylene)\n                    - 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n            or list of strings with names of quantities to use\n        threshold: float, default 0\n            threshold concentration value in [ug/l] to test on exceedence\n        verbose: Boolean\n            verbose flag (default False)\n        include: bool, default False\n            whether to include calculated values to DataFrame\n\n    Output\n    ------\n        tot_count: pd.Series\n            Total number of quantities with concentration exceeding threshold value\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'total_count()' on data\")\n        print('==============================================================')\n\n    threshold = float(threshold)\n    if threshold&lt;0:\n        raise ValueError(\"Threshold value '{}' not valid.\".format(threshold))\n\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = include)\n\n    ### sorting out which column in data to use for summation of concentrations\n    quantities, _ = determine_quantities(cols,name_list = name_list, verbose = verbose)\n\n    ### actually performing count of values above threshold:\n    try:\n        total_count = (data[quantities]&gt;threshold).sum(axis = 1)\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    if isinstance(name_list, str):\n        name_column = 'total count {}'.format(name_list)\n    elif isinstance(name_list, list):\n        name_column = 'total count selection'\n    total_count.rename(name_column,inplace = True)\n\n    if verbose:\n        print('________________________________________________________________')\n        print(\"Number of quantities out of {} exceeding \\\n              concentration of {:.2f} ug/l :\\n{}\".format(len(quantities),threshold,total_count))\n        print('--------------------------------------------------')\n\n    if include:\n        data[name_column] = total_count\n\n    return total_count\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.properties","title":"<code>properties</code>","text":"<p>Properties for Natural Attenuation Screening.</p> <p>File containing name specifications of quantities and parameters measured in groundwater samples useful for biodegredation and bioremediation analysis</p> <p>@author: A. Zech</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA","title":"<code>screening_NA</code>","text":"<p>Routines for calculating natural attenuation potential.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.electron_balance","title":"<code>electron_balance(data_frame, include=False, verbose=False, **kwargs)</code>","text":"<p>Calculating electron balance between reductors and oxidators.</p> <p>Determines ratio between the amount of electrons available and those needed for oxidation of the contaminants based on values determined by the routines \u201creductors()\u201d and \u201coxidators()\u201d.</p> <p>Ratio higher then one indicates sufficient electrons available for degredation, values smaller 1 indicates not sufficient supply of electrons to reduce the present amount of contaminants.</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.electron_balance--input","title":"Input","text":"<pre><code>data_frame: pd.DataFrame\n    tabular data containinng \"total_reductors\" and \"total_oxidators\"\n        -total amount of electrons available for reduction [mmol e-/l]\n        -total amount of electrons needed for oxidation [mmol e-/l]\ninclude: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.electron_balance--output","title":"Output","text":"<pre><code>e_bal : pd.Series\n    Ratio of electron availability: electrons available for reduction\n    devided by electrons needed for oxidation\n</code></pre> Source code in <code>mibiscreen/analysis/sample/screening_NA.py</code> <pre><code>def electron_balance(\n        data_frame,\n        include = False,\n        verbose = False,\n        **kwargs,\n        ):\n    \"\"\"Calculating electron balance between reductors and oxidators.\n\n    Determines ratio between the amount of electrons available and those\n    needed for oxidation of the contaminants based on values determined by\n    the routines \"reductors()\" and \"oxidators()\".\n\n    Ratio higher then one indicates sufficient electrons available for degredation,\n    values smaller 1 indicates not sufficient supply of electrons to reduce\n    the present amount of contaminants.\n\n    Input\n    -----\n        data_frame: pd.DataFrame\n            tabular data containinng \"total_reductors\" and \"total_oxidators\"\n                -total amount of electrons available for reduction [mmol e-/l]\n                -total amount of electrons needed for oxidation [mmol e-/l]\n        include: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        e_bal : pd.Series\n            Ratio of electron availability: electrons available for reduction\n            devided by electrons needed for oxidation\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'electron_balance()' on data\")\n        print('==============================================================')\n\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = include)\n\n    if names.name_total_reductors in cols:\n        tot_reduct = data[names.name_total_reductors]\n    else:\n        tot_reduct = reductors(data,**kwargs)\n\n    if names.name_total_oxidators in cols:\n        tot_oxi = data[names.name_total_oxidators]\n    else:\n        tot_oxi = oxidators(data,**kwargs)\n\n    e_bal = tot_reduct.div(tot_oxi, axis=0)\n    e_bal.name = names.name_e_balance\n\n    if include:\n        data[names.name_e_balance] = e_bal\n\n    if verbose:\n        print(\"Electron balance e_red/e_cont is:\\n{}\".format(e_bal))\n        print('---------------------------------')\n\n    return e_bal\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.oxidators","title":"<code>oxidators(data_frame, contaminant_group='BTEXIIN', include=False, verbose=False, **kwargs)</code>","text":"<p>Calculate the amount of electron oxidators [mmol e-/l].</p> <p>Calculates the amount of electrons needed for oxidation of the contaminants. It transformes the concentrations of contaminants to molar concentrations using molecular masses in [mg/mmol] and further identifies number of electrons from the chemical reactions using stiochiometric ratios</p> <p>alternatively: based on nitrogen and phosphate availability</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.oxidators--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    Contaminant contentrations in [ug/l], i.e. microgram per liter\ncontaminant_group: str\n    Short name for group of contaminants to use\n    default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\ninplace: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.oxidators--output","title":"Output","text":"<pre><code>tot_oxi: pd.Series\n    Total amount of electrons oxidators in [mmol e-/l]\n</code></pre> Source code in <code>mibiscreen/analysis/sample/screening_NA.py</code> <pre><code>def oxidators(\n    data_frame,\n    contaminant_group = \"BTEXIIN\",\n    include = False,\n    verbose = False,\n    **kwargs,\n    ):\n    \"\"\"Calculate the amount of electron oxidators [mmol e-/l].\n\n    Calculates the amount of electrons needed for oxidation of the contaminants.\n    It transformes the concentrations of contaminants to molar concentrations using\n    molecular masses in [mg/mmol] and further identifies number of electrons from\n    the chemical reactions using stiochiometric ratios\n\n    alternatively: based on nitrogen and phosphate availability\n\n    Input\n    -----\n        data: pd.DataFrame\n            Contaminant contentrations in [ug/l], i.e. microgram per liter\n        contaminant_group: str\n            Short name for group of contaminants to use\n            default is 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n        inplace: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        tot_oxi: pd.Series\n            Total amount of electrons oxidators in [mmol e-/l]\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'oxidators()' on data\")\n        print('==============================================================')\n\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = include)\n\n    ### sorting out which columns in data to use for summation of electrons available\n    quantities,_ = determine_quantities(cols,name_list = contaminant_group, verbose = verbose)\n\n    try:\n        tot_oxi = 0.\n        for cont in quantities:\n            cm_cont = data[cont]* 0.001/properties[cont]['molecular_mass'] # molar concentration in mmol/l\n            tot_oxi += cm_cont *  properties[cont]['factor_stoichiometry']\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    tot_oxi.rename(names.name_total_oxidators,inplace = True)\n    if verbose:\n        print(\"Total amount of oxidators per well in [mmol e-/l] is:\\n{}\".format(tot_oxi))\n        print('-----------------------------------------------------')\n\n    ### additing series to data frame\n    if include:\n        data[names.name_total_oxidators] = tot_oxi\n\n    return tot_oxi\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.reductors","title":"<code>reductors(data_frame, ea_group='ONS', include=False, verbose=False, **kwargs)</code>","text":"<p>Calculate the amount of electron reductors [mmol e-/l].</p> <p>It determines the amount of electrons availble from electron acceptors (default: mobile dissolved oxygen, nitrate, and sulfate).</p> <p>It relates concentrations to electrons using the stochimetry from the chemical reactions producting electrons and the molecular mass values for the quantities in [mg/mmol].</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.reductors--input","title":"Input","text":"<pre><code>data: pd.DataFrame\n    concentration values of electron acceptors in [mg/l]\nea_group: str\n    Short name for group of electron acceptors to use\n    default is 'ONS' (for oxygen, nitrate, and sulfate)\ninclude: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.reductors--output","title":"Output","text":"<pre><code>tot_reduct: pd.Series\nTotal amount of electrons needed for reduction in [mmol e-/l]\n</code></pre> Source code in <code>mibiscreen/analysis/sample/screening_NA.py</code> <pre><code>def reductors(\n    data_frame,\n    ea_group = 'ONS',\n    include = False,\n    verbose = False,\n    **kwargs,\n    ):\n    \"\"\"Calculate the amount of electron reductors [mmol e-/l].\n\n    It determines the amount of electrons availble from electron acceptors\n    (default: mobile dissolved oxygen, nitrate, and sulfate).\n\n    It relates concentrations to electrons using the stochimetry from the\n    chemical reactions producting electrons and the molecular mass values\n    for the quantities in [mg/mmol].\n\n    Input\n    -----\n        data: pd.DataFrame\n            concentration values of electron acceptors in [mg/l]\n        ea_group: str\n            Short name for group of electron acceptors to use\n            default is 'ONS' (for oxygen, nitrate, and sulfate)\n        include: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        tot_reduct: pd.Series\n        Total amount of electrons needed for reduction in [mmol e-/l]\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'reductors()' on data\")\n        print('==============================================================')\n\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = include)\n\n    ### sorting out which columns in data to use for summation of electrons available\n    quantities,_ = determine_quantities(cols,name_list = ea_group, verbose = verbose)\n\n    ### actually performing summation\n    try:\n        tot_reduct = 0.\n        for ea in quantities:\n            tot_reduct += properties[ea]['factor_stoichiometry']* data[ea]/properties[ea]['molecular_mass']\n    except TypeError:\n        raise ValueError(\"Data not in standardized format. Run 'standardize()' first.\")\n\n    tot_reduct.rename(names.name_total_reductors,inplace = True)\n    if verbose:\n        print(\"Total amount of electron reductors per well in [mmol e-/l] is:\\n{}\".format(tot_reduct))\n        print('----------------------------------------------------------------')\n\n    ### additing series to data frame\n    if include:\n        data[names.name_total_reductors] = tot_reduct\n\n    return tot_reduct\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.sample_NA_screening","title":"<code>sample_NA_screening(data_frame, ea_group='ONS', contaminant_group='BTEXIIN', include=False, verbose=False, **kwargs)</code>","text":"<p>Screening of NA potential for each sample in one go.</p> <p>Determines for each sample, the availability of electrons for (bio)degradation of contaminants from concentrations of (mobile dissolved) electron acceptors (default: oxygen, nitrate, sulfate). It puts them into relation to electrons needed for degradation using contaminant concentrations. Resulting electron balance is linked to a color flag/traffic light indicating status:     - green: amount of electrons available for (bio-)degradation is higher than              amount needed for degrading present contaminant mass/concentration         \u2013&gt; potential for natural attenuation     - yellow: electron balance unknown because data is not sufficient         \u2013&gt; more information needed     - red: amount of electrons available for (bio-)degradation is lower than              amount needed for degrading present contaminant mass/concentration         \u2013&gt; limited potential for natural attenuation</p> <pre><code>Sufficient supply of electrons is a prerequite for biodegradation and thus the\n</code></pre> <p>potential of natural attenuation (NA) as remediation strategy. Input</p> <pre><code>data_frame: pd.DataFrame\n    Concentration values of\n        - electron acceptors in [mg/l]\n        - contaminants in [ug/l]\nea_group: str, default 'ONS'\n    Short name for group of electron acceptors to use\n    'ONS' stands for oxygen, nitrate, sulfate and ironII\ncontaminant_group: str, default 'BTEXIIN'\n    Short name for group of contaminants to use\n    'BTEXIIN' stands for benzene, toluene, ethylbenzene, xylene,\n                           indene, indane and naphthaline\ninclude: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean, default False\n    verbose flag\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.sample_NA_screening--output","title":"Output","text":"<pre><code>na_data: pd.DataFrame\n    Tabular data with all quantities of NA screening listed per sample\n</code></pre> Source code in <code>mibiscreen/analysis/sample/screening_NA.py</code> <pre><code>def sample_NA_screening(\n    data_frame,\n    ea_group = 'ONS',\n    contaminant_group = \"BTEXIIN\",\n    include = False,\n    verbose = False,\n    **kwargs,\n    ):\n    \"\"\"Screening of NA potential for each sample in one go.\n\n    Determines for each sample, the availability of electrons for (bio)degradation of\n    contaminants from concentrations of (mobile dissolved) electron acceptors\n    (default: oxygen, nitrate, sulfate). It puts them into relation to electrons\n    needed for degradation using contaminant concentrations. Resulting electron\n    balance is linked to a color flag/traffic light indicating status:\n        - green: amount of electrons available for (bio-)degradation is higher than\n                 amount needed for degrading present contaminant mass/concentration\n            --&gt; potential for natural attenuation\n        - yellow: electron balance unknown because data is not sufficient\n            --&gt; more information needed\n        - red: amount of electrons available for (bio-)degradation is lower than\n                 amount needed for degrading present contaminant mass/concentration\n            --&gt; limited potential for natural attenuation\n\n        Sufficient supply of electrons is a prerequite for biodegradation and thus the\n    potential of natural attenuation (NA) as remediation strategy.\n    Input\n    -----\n        data_frame: pd.DataFrame\n            Concentration values of\n                - electron acceptors in [mg/l]\n                - contaminants in [ug/l]\n        ea_group: str, default 'ONS'\n            Short name for group of electron acceptors to use\n            'ONS' stands for oxygen, nitrate, sulfate and ironII\n        contaminant_group: str, default 'BTEXIIN'\n            Short name for group of contaminants to use\n            'BTEXIIN' stands for benzene, toluene, ethylbenzene, xylene,\n                                   indene, indane and naphthaline\n        include: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean, default False\n            verbose flag\n\n    Output\n    ------\n        na_data: pd.DataFrame\n            Tabular data with all quantities of NA screening listed per sample\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'sample_NA_screening()' on data\")\n        print('==============================================================')\n\n    ### check on correct data input format and extracting column names as list\n    data,_= check_data_frame(data_frame,inplace = include)\n\n    tot_reduct = reductors(data,\n                           ea_group = ea_group,\n                           include = include,\n                           verbose = verbose)\n    tot_oxi = oxidators(data,\n                        contaminant_group = contaminant_group,\n                        include = include,\n                        verbose = verbose)\n    e_bal = electron_balance(data,\n                             include = include,\n                             verbose = verbose)\n    na_traffic = sample_NA_traffic(data,\n                            contaminant_group = contaminant_group,\n                            include = include,\n                            verbose = verbose)\n\n    list_new_quantities = [tot_reduct,tot_oxi,e_bal,na_traffic]\n\n    if include is False:\n       na_data = extract_settings(data)\n\n       for add in list_new_quantities:\n           na_data.insert(na_data.shape[1], add.name, add)\n    else:\n        na_data = data\n\n    return na_data\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.sample_NA_traffic","title":"<code>sample_NA_traffic(data_frame, include=False, verbose=False, **kwargs)</code>","text":"<p>Evaluating availability of electrons for biodegredation interpreting electron balance.</p> <p>Function builds on \u2018electron_balance()\u2019, based on electron availability calculated from concentrations of contaminant and electron acceptors.</p> <p>Sufficient supply of electrons is a prerequite for biodegradation and thus the potential of natural attenuation (NA) as remediation strategy. The functions interprets the electron balance giving it a traffic light of:     - green: amount of electrons available for (bio-)degradation is higher than              amount needed for degrading present contaminant mass/concentration         \u2013&gt; potential for natural attenuation     - yellow: electron balance unknown because data is not sufficient         \u2013&gt; more information needed     - red: amount of electrons available for (bio-)degradation is lower than              amount needed for degrading present contaminant mass/concentration         \u2013&gt; limited potential for natural attenuation</p>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.sample_NA_traffic--input","title":"Input","text":"<pre><code>data_frame: pd.DataFrame\n    Ratio of electron availability\ninclude: bool, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference_analysis/#mibiscreen.analysis.sample.screening_NA.sample_NA_traffic--output","title":"Output","text":"<pre><code>traffic : pd.Series\n    Traffic light (decision) based on ratio of electron availability\n</code></pre> Source code in <code>mibiscreen/analysis/sample/screening_NA.py</code> <pre><code>def sample_NA_traffic(\n        data_frame,\n        include = False,\n        verbose = False,\n        **kwargs,\n        ):\n    \"\"\"Evaluating availability of electrons for biodegredation interpreting electron balance.\n\n    Function builds on 'electron_balance()', based on electron availability\n    calculated from concentrations of contaminant and electron acceptors.\n\n    Sufficient supply of electrons is a prerequite for biodegradation and thus the\n    potential of natural attenuation (NA) as remediation strategy. The functions\n    interprets the electron balance giving it a traffic light of:\n        - green: amount of electrons available for (bio-)degradation is higher than\n                 amount needed for degrading present contaminant mass/concentration\n            --&gt; potential for natural attenuation\n        - yellow: electron balance unknown because data is not sufficient\n            --&gt; more information needed\n        - red: amount of electrons available for (bio-)degradation is lower than\n                 amount needed for degrading present contaminant mass/concentration\n            --&gt; limited potential for natural attenuation\n\n    Input\n    -----\n        data_frame: pd.DataFrame\n            Ratio of electron availability\n        include: bool, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        traffic : pd.Series\n            Traffic light (decision) based on ratio of electron availability\n\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'sample_NA_traffic()' on data\")\n        print('==============================================================')\n\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = include)\n\n    if names.name_e_balance in cols:\n        e_balance = data[names.name_e_balance]\n    else:\n        e_balance = electron_balance(data,**kwargs)\n\n    e_bal = e_balance.values\n    traffic = np.where(e_bal&lt;1,\"red\",\"green\")\n    traffic[np.isnan(e_bal)] = \"y\"\n\n    NA_traffic = pd.Series(name =names.name_na_traffic_light,\n                           data = traffic,\n                           index = e_balance.index\n                           )\n\n    if include:\n        data[names.name_na_traffic_light] = NA_traffic\n\n    if verbose:\n        print(\"Evaluation if natural attenuation (NA) is ongoing:\")#\" for {}\".format(contaminant_group))\n        print('--------------------------------------------------')\n        print(\"Red light: Reduction is limited at {} out of {} locations\".format(\n            np.sum(traffic == \"red\"),len(e_bal)))\n        print(\"Green light: Reduction is limited at {} out of {} locations\".format(\n            np.sum(traffic == \"green\"),len(e_bal)))\n        print(\"Yellow light: No decision possible at {} out of {} locations\".format(\n            np.sum(np.isnan(e_bal)),len(e_bal)))\n        print('________________________________________________________________')\n\n    return NA_traffic\n</code></pre>"},{"location":"reference/reference_data/","title":"<code>mibiscreen.data</code> API reference","text":"<p>mibiscreen module for data handling.</p>"},{"location":"reference/reference_data/#mibiscreen.data.check_data","title":"<code>check_data</code>","text":"<p>Functions for data handling and standardization.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_columns","title":"<code>check_columns(data_frame, standardize=False, reduce=False, verbose=True)</code>","text":"<p>Function checking names of columns of data frame.</p> <p>Function that looks at the column names and links it to standard names. Optionally, it renames identified column names to the standard names of the model.</p> <pre><code>data_frame: pd.DataFrame\n    dataframe with the measurements\nstandardize: Boolean, default False\n    Whether to standardize identified column names\nreduce: Boolean, default False\n    Whether to reduce data to known quantities\nverbose: Boolean, default True\n    verbosity flag\n</code></pre> <pre><code>tuple: three list containing names of\n        list with identitied quantities in data (but not standardized names)\n        list with unknown quantities in data (not in list of standardized names)\n        list with standard names of identified quantities\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_columns--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_columns--example","title":"Example:","text":"<p>Todo\u2019s:     - complete list of potential contaminants, environmental factors     - add name check for metabolites?</p> Source code in <code>mibiscreen/data/check_data.py</code> <pre><code>def check_columns(data_frame,\n                  standardize = False,\n                  reduce = False,\n                  verbose = True):\n    \"\"\"Function checking names of columns of data frame.\n\n    Function that looks at the column names and links it to standard names.\n    Optionally, it renames identified column names to the standard names of the model.\n\n    Args:\n    -------\n        data_frame: pd.DataFrame\n            dataframe with the measurements\n        standardize: Boolean, default False\n            Whether to standardize identified column names\n        reduce: Boolean, default False\n            Whether to reduce data to known quantities\n        verbose: Boolean, default True\n            verbosity flag\n\n    Returns:\n    -------\n        tuple: three list containing names of\n                list with identitied quantities in data (but not standardized names)\n                list with unknown quantities in data (not in list of standardized names)\n                list with standard names of identified quantities\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    Todo's:\n        - complete list of potential contaminants, environmental factors\n        - add name check for metabolites?\n    \"\"\"\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'check_columns()' on data\")\n        print('==============================================================')\n\n    data,cols= check_data_frame(data_frame,\n                                sample_name_to_index = False,\n                                inplace = True)\n\n    results = standard_names(cols,\n                             standardize = False,\n                             reduce = False,\n                             verbose = False,\n                             )\n\n    column_names_standard = results[0]\n    column_names_known = results[1]\n    column_names_unknown = results[2]\n    column_names_transform = results[3]\n\n    if standardize:\n        data.columns = [column_names_transform.get(x, x) for x in data.columns]\n\n    if reduce:\n        data.drop(labels = column_names_unknown,axis = 1,inplace=True)\n\n    if verbose:\n        print(\"{} quantities identified in provided data.\".format(len(column_names_known)))\n        print(\"List of names with standard names:\")\n        print('----------------------------------')\n        for i,name in enumerate(column_names_known):\n            print(name,\" --&gt; \",column_names_standard[i])\n        print('----------------------------------')\n        if standardize:\n            print(\"Identified column names have been standardized\")\n        else:\n            print(\"\\nRenaming can be done by setting keyword 'standardize' to True.\\n\")\n        print('________________________________________________________________')\n        print(\"{} quantities have not been identified in provided data:\".format(len(column_names_unknown)))\n        print('---------------------------------------------------------')\n        for i,name in enumerate(column_names_unknown):\n            print(name)\n        print('---------------------------------------------------------')\n        if reduce:\n            print(\"Not identified quantities have been removed from data frame\")\n        else:\n            print(\"\\nReduction to known quantities can be done by setting keyword 'reduce' to True.\\n\")\n        print('================================================================')\n\n    return (column_names_known,column_names_unknown,column_names_standard)\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_data_frame","title":"<code>check_data_frame(data_frame, sample_name_to_index=False, inplace=False)</code>","text":"<p>Checking data on correct format.</p> <p>Tests if provided data is a pandas data frame and provides column names. Optionally it sets the sample name as index.</p>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_data_frame--input","title":"Input","text":"<pre><code>data_frame: pd.DataFrame\n    quantities for data analysis given per sample\nsample_name_to_index:  Boolean, default False\n    Whether to set the sample name to the index of the DataFrame\ninplace: Boolean, default False\n    Whether to modify the DataFrame rather than creating a new one.\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_data_frame--output","title":"Output","text":"<pre><code>data: pd.DataFrame\n    copy of given dataframe with index set to sample name\ncols: list\n    List of column names\n</code></pre> Source code in <code>mibiscreen/data/check_data.py</code> <pre><code>def check_data_frame(data_frame,\n                     sample_name_to_index = False,\n                     inplace = False,\n                     ):\n    \"\"\"Checking data on correct format.\n\n    Tests if provided data is a pandas data frame and provides column names.\n    Optionally it sets the sample name as index.\n\n    Input\n    -----\n        data_frame: pd.DataFrame\n            quantities for data analysis given per sample\n        sample_name_to_index:  Boolean, default False\n            Whether to set the sample name to the index of the DataFrame\n        inplace: Boolean, default False\n            Whether to modify the DataFrame rather than creating a new one.\n\n    Output\n    ------\n        data: pd.DataFrame\n            copy of given dataframe with index set to sample name\n        cols: list\n            List of column names\n    \"\"\"\n    if not isinstance(data_frame, pd.DataFrame):\n        raise ValueError(\"Data has to be a panda-DataFrame or Series \\\n                          but is given as type {}\".format(type(data_frame)))\n\n    if inplace is False:\n        data = data_frame.copy()\n    else:\n        data = data_frame\n\n    if sample_name_to_index:\n        if names.name_sample not in data.columns:\n            print(\"Warning: No sample name provided for making index. Consider standardizing data first\")\n        else:\n            data.set_index(names.name_sample,inplace = True)\n\n    if isinstance(data, pd.Series):\n        cols = [data.name]\n    else:\n        cols = data.columns.to_list()\n\n    return data, cols\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_units","title":"<code>check_units(data, verbose=True)</code>","text":"<p>Function to check the units of the measurements.</p> <pre><code>data: pandas.DataFrames\n    dataframe with the measurements where first row contains\n    the units or a dataframe with only the column names and units\nverbose: Boolean\n    verbose statement (default True)\n</code></pre> <pre><code>col_check_list: list\n    quantities whose units need checking/correction\n</code></pre> <pre><code>None (yet).\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_units--example","title":"Example:","text":"<pre><code>To be added.\n</code></pre> Source code in <code>mibiscreen/data/check_data.py</code> <pre><code>def check_units(data,\n                verbose = True):\n    \"\"\"Function to check the units of the measurements.\n\n    Args:\n    -------\n        data: pandas.DataFrames\n            dataframe with the measurements where first row contains\n            the units or a dataframe with only the column names and units\n        verbose: Boolean\n            verbose statement (default True)\n\n    Returns:\n    -------\n        col_check_list: list\n            quantities whose units need checking/correction\n\n    Raises:\n    -------\n        None (yet).\n\n    Example:\n    -------\n        To be added.\n    \"\"\"\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'check_units()' on data\")\n        print('================================================================')\n\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Provided data is not a data frame.\")\n    elif data.shape[0]&gt;1:\n        units = data.drop(labels = np.arange(1,data.shape[0]))\n    else:\n        units = data.copy()\n\n    units_in_data = set(map(lambda x: str(x).lower(), units.iloc[0,:].values))\n    ### testing if provided data frame contains any unit\n    test_unit = False\n    for u in all_units:\n        if u in units_in_data:\n            test_unit = True\n            break\n    if not test_unit:\n        raise ValueError(\"Error: The second line in the dataframe is supposed\\\n                         to specify the units. No units were detected in this\\\n                         line, check https://mibipret.github.io/mibiscreen/ Data\\\n                         documentation.\")\n\n    # standardize column names (as it might not has happened for data yet)\n    check_columns(units,standardize = True, verbose = False)\n    col_check_list= []\n\n    for quantity in units.columns:\n        if quantity in names.geochemicals['chemical_composition']:\n            if str(units[quantity][0]).lower() not in standard_units['mgperl']:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be milligramm per liter (e.g. {}).\"\n                              .format(quantity,units[quantity][0],standard_units['mgperl'][0]))\n\n        if quantity in names.contaminants['all_cont']:\n            if str(units[quantity][0]).lower() not in standard_units['microgperl']:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be microgramm per liter (e.g. {}).\"\n                              .format(quantity,units[quantity][0],standard_units['microgperl'][0]))\n\n        if quantity in list(units_env_cond.keys()):\n            unit_type = units_env_cond[quantity]\n            if str(units[quantity][0]).lower() not in standard_units[unit_type]:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be in {} (e.g. {}).\".format(\n                            quantity,units[quantity][0],unit_type,standard_units[unit_type][0]))\n\n        if quantity.split('-')[0] in names.isotopes:\n            if str(units[quantity][0]).lower() not in standard_units['permil']:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be per mille (e.g. {}).\"\n                              .format(quantity,units[quantity][0],standard_units['permil'][0]))\n\n        if quantity in names.metabolites:\n            if str(units[quantity][0]).lower() not in standard_units['microgperl']:\n                col_check_list.append(quantity)\n                if verbose:\n                    print(\"Warning: Check unit of {}!\\n Given in {}, but must be microgramm per liter (e.g. {}).\"\n                              .format(quantity,units[quantity][0],standard_units['microgperl'][0]))\n\n    if verbose:\n        print('________________________________________________________________')\n        if len(col_check_list) == 0:\n            print(\" All identified quantities given in requested units.\")\n        else:\n            print(\" All other identified quantities given in requested units.\")\n        print('================================================================')\n\n    return col_check_list\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_values","title":"<code>check_values(data_frame, inplace=False, verbose=True)</code>","text":"<p>Function that checks on value types and replaces non-measured values.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements (without first row of units)\ninplace: Boolean, default False\n    Whether to modify the DataFrame rather than creating a new one.\nverbose: Boolean\n    verbose statement (default True)\n</code></pre> <pre><code>data_pure: pandas.DataFrame\n    Tabular data with standard column names and without units\n</code></pre> <pre><code>None (yet).\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.check_values--example","title":"Example:","text":"<pre><code>To be added.\n</code></pre> Source code in <code>mibiscreen/data/check_data.py</code> <pre><code>def check_values(data_frame,\n                 inplace = False,\n                 verbose = True,\n                 ):\n    \"\"\"Function that checks on value types and replaces non-measured values.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements (without first row of units)\n        inplace: Boolean, default False\n            Whether to modify the DataFrame rather than creating a new one.\n        verbose: Boolean\n            verbose statement (default True)\n\n    Returns:\n    -------\n        data_pure: pandas.DataFrame\n            Tabular data with standard column names and without units\n\n    Raises:\n    -------\n        None (yet).\n\n    Example:\n    -------\n        To be added.\n    \"\"\"\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'check_values()' on data\")\n        print('================================================================')\n\n    data,cols= check_data_frame(data_frame, inplace = inplace)\n\n    ### testing if provided data frame contains first row with units\n    for u in data.iloc[0].to_list():\n        if u in all_units:\n            print(\"WARNING: First row identified as units, has been removed for value check\")\n            print('________________________________________________________________')\n            data.drop(labels = 0,inplace = True)\n            break\n\n    for sign in to_replace_list:\n        data.iloc[:,:] = data.iloc[:,:].replace(to_replace=sign, value=to_replace_value)\n\n    # standardize column names (as it might not has happened for data yet)\n    # check_columns(data,\n    #               standardize = True,\n    #               check_metabolites=True,\n    #               verbose = False)\n\n    # transform data to numeric values\n    quantities_transformed = []\n    for quantity in cols: #data.columns:\n        try:\n            # data_pure.loc[:,quantity] = pd.to_numeric(data_pure.loc[:,quantity])\n            data[quantity] = pd.to_numeric(data[quantity])\n            quantities_transformed.append(quantity)\n        except ValueError:\n            print(\"WARNING: Cound not transform '{}' to numerical values\".format(quantity))\n            print('________________________________________________________________')\n    if verbose:\n        print(\"Quantities with values transformed to numerical (int/float):\")\n        print('-----------------------------------------------------------')\n        for name in quantities_transformed:\n            print(name)\n        print('================================================================')\n\n    return data\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.standard_names","title":"<code>standard_names(name_list, standardize=True, reduce=False, verbose=False)</code>","text":"<p>Function transforming list of names to standard names.</p> <p>Function that looks at the names (of e.g. environmental variables, contaminants, metabolites, isotopes, etc) and provides the corresponding standard names.</p> <pre><code>name_list: string or list of strings\n    names of quantities to be transformed to standard\nstandardize: Boolean, default False\n    Whether to standardize identified column names\nreduce: Boolean, default False\n    Whether to reduce data to known quantities\nverbose: Boolean, default True\n    verbosity flag\n</code></pre> <pre><code>tuple: three list containing names of\n        list with identitied quantities in data (but not standardized names)\n        list with unknown quantities in data (not in list of standardized names)\n        list with standard names of identified quantities\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.standard_names--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.standard_names--example","title":"Example:","text":"<p>Todo\u2019s:     - complete list of potential contaminants, environmental factors     - add name check for metabolites?</p> Source code in <code>mibiscreen/data/check_data.py</code> <pre><code>def standard_names(name_list,\n                   standardize = True,\n                   reduce = False,\n                   verbose = False,\n                   ):\n    \"\"\"Function transforming list of names to standard names.\n\n    Function that looks at the names (of e.g. environmental variables, contaminants,\n    metabolites, isotopes, etc) and provides the corresponding standard names.\n\n    Args:\n    -------\n        name_list: string or list of strings\n            names of quantities to be transformed to standard\n        standardize: Boolean, default False\n            Whether to standardize identified column names\n        reduce: Boolean, default False\n            Whether to reduce data to known quantities\n        verbose: Boolean, default True\n            verbosity flag\n\n    Returns:\n    -------\n        tuple: three list containing names of\n                list with identitied quantities in data (but not standardized names)\n                list with unknown quantities in data (not in list of standardized names)\n                list with standard names of identified quantities\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    Todo's:\n        - complete list of potential contaminants, environmental factors\n        - add name check for metabolites?\n    \"\"\"\n    names_standard = []\n    names_known = []\n    names_unknown = []\n    names_transform = {}\n\n    dict_names = names.col_dict.copy()\n\n    if isinstance(name_list, str):\n        name_list = [name_list]\n    elif isinstance(name_list, list):\n        for name in name_list:\n            if not isinstance(name, str):\n                raise ValueError(\"Entry in provided list of names is not a string:\", name)\n\n    for x in name_list:\n        y = dict_names.get(x, False)\n        x_isotope = x.split('-')[0]\n        y_isotopes = names.names_isotopes.get(x_isotope.lower(), False)\n\n        if y_isotopes is not False:\n            x_molecule = x.removeprefix(x_isotope+'-')\n            y_molecule = names.names_contaminants.get(x_molecule.lower(), False)\n            if y_molecule is False:\n                names_unknown.append(x)\n            else:\n                y = y_isotopes+'-'+y_molecule\n                names_known.append(x)\n                names_standard.append(y)\n                names_transform[x] = y\n        else:\n            y = dict_names.get(x.lower(), False)\n            if y is False:\n                names_unknown.append(x)\n            else:\n                names_known.append(x)\n                names_standard.append(y)\n                names_transform[x] = y\n\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'standard_names()'\")\n        print('================================================================')\n        print(\"{} of {} quantities identified in name list.\".format(len(names_known),len(name_list)))\n        print(\"List of names with standard names:\")\n        print('----------------------------------')\n        for i,name in enumerate(names_known):\n            print(name,\" --&gt; \",names_standard[i])\n        print('----------------------------------')\n        if standardize:\n            print(\"Identified column names have been standardized\")\n        else:\n            print(\"\\nRenaming can be done by setting keyword 'standardize' to True.\\n\")\n        print('________________________________________________________________')\n        print(\"{} quantities have not been identified in provided data:\".format(len(names_unknown)))\n        print('---------------------------------------------------------')\n        for i,name in enumerate(names_unknown):\n            print(name)\n        print('---------------------------------------------------------')\n        if reduce:\n            print(\"Not identified quantities have been removed from data frame\")\n        else:\n            print(\"\\nReduction to known quantities can be done by setting keyword 'reduce' to True.\\n\")\n        print('================================================================')\n\n    if standardize:\n        if reduce:\n            return names_standard\n        else:\n            return names_standard + names_unknown\n    else:\n        return (names_standard, names_known, names_unknown, names_transform)\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.standardize","title":"<code>standardize(data_frame, reduce=True, store_csv=False, verbose=True)</code>","text":"<p>Function providing condensed data frame with standardized names.</p> <p>Function is checking names of columns and renames columns, condenses data to identified column names, checks units and  names sof data frame.</p> <p>Function that looks at the column names and renames the columns to the standard names of the model.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements\ncheck_metabolites: Boolean, default False\n    whether to check on metabolites' values\nreduce: Boolean, default True\n    whether to reduce data to known quantities (default True),\n    otherwise full dataframe with renamed columns (for those identifyable) is returned\nstore_csv: Boolean, default False\n    whether to save dataframe in standard format to csv-file\nverbose: Boolean, default True\n    verbose statement\n</code></pre> <pre><code>data_numeric, units: pandas.DataFrames\n    Tabular data with standardized column names, values in numerics etc\n    and table with units for standardized column names\n</code></pre> <pre><code>None (yet).\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.check_data.standardize--example","title":"Example:","text":"<p>Todo\u2019s:     - complete list of potential contaminants, environmental factors     - add name check for metabolites?     - add key-word to specify which data to extract         (i.e. data columns to return)</p> Source code in <code>mibiscreen/data/check_data.py</code> <pre><code>def standardize(data_frame,\n                reduce = True,\n                store_csv = False,\n                verbose=True,\n                ):\n    \"\"\"Function providing condensed data frame with standardized names.\n\n    Function is checking names of columns and renames columns,\n    condenses data to identified column names, checks units and  names\n    sof data frame.\n\n    Function that looks at the column names and renames the columns to\n    the standard names of the model.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements\n        check_metabolites: Boolean, default False\n            whether to check on metabolites' values\n        reduce: Boolean, default True\n            whether to reduce data to known quantities (default True),\n            otherwise full dataframe with renamed columns (for those identifyable) is returned\n        store_csv: Boolean, default False\n            whether to save dataframe in standard format to csv-file\n        verbose: Boolean, default True\n            verbose statement\n\n    Returns:\n    -------\n        data_numeric, units: pandas.DataFrames\n            Tabular data with standardized column names, values in numerics etc\n            and table with units for standardized column names\n\n    Raises:\n    -------\n        None (yet).\n\n    Example:\n    -------\n    Todo's:\n        - complete list of potential contaminants, environmental factors\n        - add name check for metabolites?\n        - add key-word to specify which data to extract\n            (i.e. data columns to return)\n\n    \"\"\"\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'standardize()' on data\")\n        print('================================================================')\n        print(' Function performing check of data including:')\n        print('  * check of column names and standardizing them.')\n        print('  * check of units and outlining which to adapt.')\n        print('  * check of values, replacing empty values by nan \\n    and making them numeric')\n\n    data,cols= check_data_frame(data_frame,\n                                sample_name_to_index = False,\n                                inplace = False)\n\n    # general column check &amp; standardize column names\n    check_columns(data,\n                  standardize = True,\n                  reduce = reduce,\n                  verbose = verbose)\n\n    # general unit check\n    units = data.drop(labels = np.arange(1,data.shape[0]))\n    col_check_list = check_units(units,\n                                 verbose = verbose)\n\n    # transform data to numeric values\n    data_numeric = check_values(data.drop(labels = 0),\n                                inplace = False,\n                                verbose = verbose)\n\n    # store standard data to file\n    if store_csv:\n        if len(col_check_list) != 0:\n            print('________________________________________________________________')\n            print(\"Data could not be saved because not all identified \\n quantities are given in requested units.\")\n        else:\n            try:\n                data.to_csv(store_csv,index=False)\n                if verbose:\n                    print('________________________________________________________________')\n                    print(\"Save standardized dataframe to file:\\n\", store_csv)\n            except OSError:\n                print(\"WARNING: data could not be saved. Check provided file path and name: {}\".format(store_csv))\n    if verbose:\n        print('================================================================')\n\n    return data_numeric, units\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.example_data","title":"<code>example_data</code>","text":"<p>Example dat.</p> <p>Measurements on quantities and parameters in groundwater samples used for biodegredation and bioremediation analysis.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_data/#mibiscreen.data.example_data.example_data","title":"<code>example_data(data_type='all', with_units=False)</code>","text":"<p>Function provinging test data for mibiscreen data analysis.</p> <pre><code>data_type: string\n    Type of data to return:\n        -- \"all\": all types of data available\n        -- \"set_env_cont\": well setting, environmental and contaminants data\n        -- \"setting\": well setting data only\n        -- \"environment\": data on environmental\n        -- \"contaminants\": data on contaminants\n        -- \"metabolites\": data on metabolites\n        -- \"isotopes\": data on isotopes\n        -- \"hydro\": data on hydrogeolocial conditions\nwith_units: Boolean, default False\n    flag to provide first row with units\n    if False (no units), values in columns will be numerical\n    if True (with units), values in columns will be objects\n</code></pre> <pre><code>pandas.DataFrame: Tabular data with standard column names\n</code></pre> <pre><code>None\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.example_data.example_data--example","title":"Example:","text":"<pre><code>To be added!\n</code></pre> Source code in <code>mibiscreen/data/example_data.py</code> <pre><code>def example_data(data_type = 'all',\n                 with_units = False,\n                 ):\n    \"\"\"Function provinging test data for mibiscreen data analysis.\n\n    Args:\n    -------\n        data_type: string\n            Type of data to return:\n                -- \"all\": all types of data available\n                -- \"set_env_cont\": well setting, environmental and contaminants data\n                -- \"setting\": well setting data only\n                -- \"environment\": data on environmental\n                -- \"contaminants\": data on contaminants\n                -- \"metabolites\": data on metabolites\n                -- \"isotopes\": data on isotopes\n                -- \"hydro\": data on hydrogeolocial conditions\n        with_units: Boolean, default False\n            flag to provide first row with units\n            if False (no units), values in columns will be numerical\n            if True (with units), values in columns will be objects\n\n    Returns:\n    -------\n        pandas.DataFrame: Tabular data with standard column names\n\n    Raises:\n    -------\n        None\n\n    Example:\n    -------\n        To be added!\n    \"\"\"\n    mgl = standard_units['mgperl'][0]\n    microgl = standard_units['microgperl'][0]\n\n    setting = [names.name_sample,names.name_observation_well,names.name_sample_depth]\n    setting_units = [' ',' ',standard_units['meter'][0]]\n    setting_s01 = ['2000-001', 'B-MLS1-3-12', -12.]\n    setting_s02 = ['2000-002', 'B-MLS1-5-15', -15.5]\n    setting_s03 = ['2000-003', 'B-MLS1-6-17', -17.]\n    setting_s04 = ['2000-004', 'B-MLS1-7-19', -19.]\n\n    environment = [names.name_pH,\n                   names.name_EC,\n                   names.name_redox,\n                   names.name_oxygen,\n                   names.name_nitrate,\n                   names.name_nitrite,\n                   names.name_sulfate,\n                   names.name_ammonium,\n                   names.name_sulfide,\n                   names.name_methane,\n                   names.name_ironII,\n                   names.name_manganese,\n                   names.name_phosphate]\n\n    environment_units = [' ',standard_units['microsimpercm'][0],standard_units['millivolt'][0],\n                         mgl,mgl,mgl,mgl,mgl,mgl,mgl,mgl,mgl,mgl]\n    environment_s01 = [7.23, 322., -208.,0.3,122.,0.58, 23., 5., 0., 748., 3., 1.,1.6]\n    environment_s02 = [7.67, 405., -231.,0.9,5.,0.0, 0., 6., 0., 2022., 1., 0.,0]\n    environment_s03 = [7.75, 223., -252.,0.1,3.,0.03, 1., 13., 0., 200., 1., 0.,0.8]\n    environment_s04 = [7.53, 58., -317.,0., 180.,1., 9., 15., 6., 122., 0., 0.,0.1]\n\n    contaminants = [names.name_benzene,\n                    names.name_toluene,\n                    names.name_ethylbenzene,\n                    names.name_pm_xylene,\n                    names.name_o_xylene,\n                    names.name_indane,\n                    names.name_indene,\n                    names.name_naphthalene]\n\n    contaminants_units = [microgl,microgl,microgl,microgl,\n                          microgl,microgl,microgl,microgl]\n    contaminants_s01 = [263., 2., 269., 14., 51., 1254., 41., 2207.]\n    contaminants_s02 = [179., 7., 1690., 751., 253., 1352., 15., 5410.]\n    contaminants_s03 = [853., 17., 1286., 528., 214., 1031., 31., 3879.]\n    contaminants_s04 = [1254., 10., 1202., 79., 61., 814., 59., 1970.]\n\n    metabolites = [names.name_phenol,\n                   names.name_cinnamic_acid,\n                   names.name_benzoic_acid]\n\n    metabolites_units = [microgl,microgl,microgl]\n    metabolites_s01 = [0.2, 0.4, 1.4]\n    metabolites_s02 = [np.nan, 0.1, 0.]\n    metabolites_s03 = [0., 11.4, 5.4]\n    metabolites_s04 = [0.3, 0.5, 0.7]\n\n    # isotopes = ['delta_13C-benzene','delta_2H-benzene']\n    isotopes = [names.name_13C+'-'+names.name_benzene,\n                names.name_2H+'-'+names.name_benzene,\n                ]\n\n    isotopes_units = [standard_units['permil'][0],standard_units['permil'][0]]\n    isotopes_s01 = [-26.1,-106.]\n    isotopes_s02 = [-25.8,-110.]\n    isotopes_s03 = [-24.1,-118.]\n    isotopes_s04 = [-24.1,-117.]\n\n    if  data_type == 'setting':\n        data = pd.DataFrame([setting_units,setting_s01,setting_s02,setting_s03,\n                             setting_s04],columns = setting)\n\n    elif  data_type == 'environment':\n        units = setting_units+environment_units\n        columns = setting+environment\n        sample_01 = setting_s01+environment_s01\n        sample_02 = setting_s02+environment_s02\n        sample_03 = setting_s03+environment_s03\n        sample_04 = setting_s04+environment_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif  data_type == 'contaminants':\n        units = setting_units+contaminants_units\n        columns = setting+contaminants\n        sample_01 = setting_s01+contaminants_s01\n        sample_02 = setting_s02+contaminants_s02\n        sample_03 = setting_s03+contaminants_s03\n        sample_04 = setting_s04+contaminants_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif  data_type == 'metabolites':\n\n        units = setting_units+metabolites_units\n        columns = setting+metabolites\n        sample_01 = setting_s01+metabolites_s01\n        sample_02 = setting_s02+metabolites_s02\n        sample_03 = setting_s03+metabolites_s03\n        sample_04 = setting_s04+metabolites_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif  data_type == 'isotopes':\n\n        units = setting_units+isotopes_units\n        columns = setting+isotopes\n        sample_01 = setting_s01+isotopes_s01\n        sample_02 = setting_s02+isotopes_s02\n        sample_03 = setting_s03+isotopes_s03\n        sample_04 = setting_s04+isotopes_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif data_type == \"set_env_cont\":\n\n        units = setting_units+environment_units+contaminants_units\n        columns = setting+environment+contaminants\n        sample_01 = setting_s01+environment_s01+contaminants_s01\n        sample_02 = setting_s02+environment_s02+contaminants_s02\n        sample_03 = setting_s03+environment_s03+contaminants_s03\n        sample_04 = setting_s04+environment_s04+contaminants_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    elif data_type == 'all':\n        units = setting_units+environment_units+contaminants_units+metabolites_units + isotopes_units\n        columns = setting+environment+contaminants+metabolites + isotopes\n        sample_01 = setting_s01+environment_s01+contaminants_s01+metabolites_s01+isotopes_s01\n        sample_02 = setting_s02+environment_s02+contaminants_s02+metabolites_s02+isotopes_s02\n        sample_03 = setting_s03+environment_s03+contaminants_s03+metabolites_s03+isotopes_s03\n        sample_04 = setting_s04+environment_s04+contaminants_s04+metabolites_s04+isotopes_s04\n\n        data = pd.DataFrame([units,sample_01,sample_02,sample_03,sample_04],\n                            columns = columns)\n\n    else:\n        raise ValueError(\"Specified data type '{}' not available\".format(data_type))\n\n    if not with_units:\n        data.drop(0,inplace = True)\n        for quantity in data.columns[2:]:\n            data[quantity] = pd.to_numeric(data[quantity])\n\n    return data\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.load_data","title":"<code>load_data</code>","text":"<p>Functions for data I/O handling.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_data/#mibiscreen.data.load_data.load_csv","title":"<code>load_csv(file_path=None, verbose=False, store_provenance=False)</code>","text":"<p>Function to load data from csv file.</p> <pre><code>file_path: str\n    Name of the path to the file\nverbose: Boolean\n    verbose flag\nstore_provenance: Boolean\n    To add!\n</code></pre> <pre><code>data: pd.DataFrame\n    Tabular data\nunits: pd.DataFrame\n    Tabular data on units\n</code></pre> <pre><code>ValueError: If `file_path` is not a valid file location\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.load_data.load_csv--example","title":"Example:","text":"<p>This function can be called with the file path of the example data as    argument using:</p> <pre><code>&gt;&gt;&gt; from mibiscreen.data import load_excel\n&gt;&gt;&gt; load_excel(example_data.csv)\n</code></pre> Source code in <code>mibiscreen/data/load_data.py</code> <pre><code>def load_csv(\n        file_path = None,\n        verbose = False,\n        store_provenance = False,\n        ):\n    \"\"\"Function to load data from csv file.\n\n    Args:\n    -------\n        file_path: str\n            Name of the path to the file\n        verbose: Boolean\n            verbose flag\n        store_provenance: Boolean\n            To add!\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            Tabular data\n        units: pd.DataFrame\n            Tabular data on units\n\n    Raises:\n    -------\n        ValueError: If `file_path` is not a valid file location\n\n    Example:\n    -------\n       This function can be called with the file path of the example data as\n       argument using:\n\n        &gt;&gt;&gt; from mibiscreen.data import load_excel\n        &gt;&gt;&gt; load_excel(example_data.csv)\n\n    \"\"\"\n    if file_path is None:\n        raise ValueError('Specify file path and file name!')\n    if not os.path.isfile(file_path):\n        raise OSError('Cannot access file at : ',file_path)\n\n    data = pd.read_csv(file_path, encoding=\"unicode_escape\")\n    if \";\" in data.iloc[1].iloc[0]:\n        data = pd.read_csv(file_path, sep=\";\", encoding=\"unicode_escape\")\n    units = data.drop(labels = np.arange(1,data.shape[0]))\n\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'load_csv()' on data file \", file_path)\n        print('================================================================')\n        print(\"Units of quantities:\")\n        print('-------------------')\n        print(units)\n        print('________________________________________________________________')\n        print(\"Loaded data as pandas DataFrame:\")\n        print('--------------------------------')\n        print(data)\n        print('================================================================')\n\n    return data, units\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.load_data.load_excel","title":"<code>load_excel(file_path=None, sheet_name=0, verbose=False, store_provenance=False, **kwargs)</code>","text":"<p>Function to load data from excel file.</p> <pre><code>file_path: str\n    Name of the path to the file\nsheet_name: int\n    Number of the sheet in the excel file to load\nverbose: Boolean\n    verbose flag\nstore_provenance: Boolean\n    To add!\n**kwargs: optional keyword arguments to pass to pandas' routine\n    read_excel()\n</code></pre> <pre><code>data: pd.DataFrame\n    Tabular data\nunits: pd.DataFrame\n    Tabular data on units\n</code></pre> <pre><code>ValueError: If `file_path` is not a valid file location\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.load_data.load_excel--example","title":"Example:","text":"<p>This function can be called with the file path of the example data as    argument using:</p> <pre><code>&gt;&gt;&gt; from mibiscreen.data import load_excel\n&gt;&gt;&gt; load_excel(example_data.xlsx)\n</code></pre> Source code in <code>mibiscreen/data/load_data.py</code> <pre><code>def load_excel(\n        file_path = None,\n        sheet_name = 0,\n        verbose = False,\n        store_provenance = False,\n        **kwargs,\n        ):\n    \"\"\"Function to load data from excel file.\n\n    Args:\n    -------\n        file_path: str\n            Name of the path to the file\n        sheet_name: int\n            Number of the sheet in the excel file to load\n        verbose: Boolean\n            verbose flag\n        store_provenance: Boolean\n            To add!\n        **kwargs: optional keyword arguments to pass to pandas' routine\n            read_excel()\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            Tabular data\n        units: pd.DataFrame\n            Tabular data on units\n\n    Raises:\n    -------\n        ValueError: If `file_path` is not a valid file location\n\n    Example:\n    -------\n       This function can be called with the file path of the example data as\n       argument using:\n\n        &gt;&gt;&gt; from mibiscreen.data import load_excel\n        &gt;&gt;&gt; load_excel(example_data.xlsx)\n\n    \"\"\"\n    if file_path is None:\n        raise ValueError('Specify file path and file name!')\n    if not os.path.isfile(file_path):\n        raise OSError('Cannot access file at : ',file_path)\n\n    data = pd.read_excel(file_path,\n                         sheet_name = sheet_name,\n                         **kwargs)\n    if \";\" in data.iloc[1].iloc[0]:\n        data = pd.read_excel(file_path,\n                             sep=\";\",\n                             sheet_name = sheet_name,\n                             **kwargs)\n\n    units = data.drop(labels = np.arange(1,data.shape[0]))\n\n    if verbose:\n        print('==============================================================')\n        print(\" Running function 'load_excel()' on data file \", file_path)\n        print('==============================================================')\n        print(\"Unit of quantities:\")\n        print('-------------------')\n        print(units)\n        print('________________________________________________________________')\n        print(\"Loaded data as pandas DataFrame:\")\n        print('--------------------------------')\n        print(data)\n        print('================================================================')\n\n    return data, units\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.names_data","title":"<code>names_data</code>","text":"<p>Name specifications of data!</p> <p>File containing name specifications of quantities and parameters measured in groundwater samples useful for biodegredation and bioremediation analysis</p> <p>@author: A. Zech</p>"},{"location":"reference/reference_data/#mibiscreen.data.set_data","title":"<code>set_data</code>","text":"<p>Functions for data extraction and merging in preparation of analysis and plotting.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.compare_lists","title":"<code>compare_lists(list1, list2, verbose=False)</code>","text":"<p>Checking overlap of two given list.</p>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.compare_lists--input","title":"Input","text":"<pre><code>list1: list of strings\n    given extensive list (usually column names of a pd.DataFrame)\nlist2: list of strings\n    list of names to extract/check overlap with strings in list 'column'\nverbose: Boolean, default True\n    verbosity flag\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.compare_lists--output","title":"Output","text":"<pre><code>(intersection, remainder_list1, reminder_list2): tuple of lists\n    * intersection: list of strings present in both lists 'list1' and 'list2'\n    * remainder_list1: list of strings only present in 'list1'\n    * remainder_list2: list of strings only present in 'list2'\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.compare_lists--example","title":"Example:","text":"<p>list1 = [\u2018test1\u2019,\u2019test2\u2019] list2 =  [\u2018test1\u2019,\u2019test3\u2019]</p> <p>([\u2018test1\u2019],[\u2018test2\u2019]['test3']) = compare_lists(list1,list2)</p> Source code in <code>mibiscreen/data/set_data.py</code> <pre><code>def compare_lists(list1,\n                  list2,\n                  verbose = False,\n                  ):\n    \"\"\"Checking overlap of two given list.\n\n    Input\n    -----\n        list1: list of strings\n            given extensive list (usually column names of a pd.DataFrame)\n        list2: list of strings\n            list of names to extract/check overlap with strings in list 'column'\n        verbose: Boolean, default True\n            verbosity flag\n\n    Output\n    ------\n        (intersection, remainder_list1, reminder_list2): tuple of lists\n            * intersection: list of strings present in both lists 'list1' and 'list2'\n            * remainder_list1: list of strings only present in 'list1'\n            * remainder_list2: list of strings only present in 'list2'\n\n    Example:\n    -------\n    list1 = ['test1','test2']\n    list2 =  ['test1','test3']\n\n    (['test1'],['test2']['test3']) = compare_lists(list1,list2)\n\n    \"\"\"\n    intersection = list(set(list1) &amp; set(list2))\n    remainder_list1 = list(set(list1) - set(list2))\n    remainder_list2 = list(set(list2) - set(list1))\n\n    if verbose:\n        print('================================================================')\n        print(\" Running function 'extract_variables()'\")\n        print('================================================================')\n        print(\"strings present in both lists:\", intersection)\n        print(\"strings only present in either of the lists:\", remainder_list1 +  remainder_list2)\n\n    return (intersection,remainder_list1,remainder_list2)\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.determine_quantities","title":"<code>determine_quantities(cols, name_list='all', verbose=False)</code>","text":"<p>Select a subset of column names (from DataFrame).</p>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.determine_quantities--input","title":"Input","text":"<pre><code>cols: list\n    Names of quantities (column names) from pd.DataFrame\nname_list: str or list of str, default is 'all'\n    quantities to extract from column names.\n\n    If a list of strings is provided, these will be selected from the list of column names (col)\n    If a string is provided, this is a short name for a specific group of quantities:\n        - 'all' (all quantities given in data frame except settings)\n        - short name for group of contaminants:\n            - 'BTEX' (for benzene, toluene, ethylbenzene, xylene)\n            - 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                          indene, indane and naphthaline)\n            - 'all_cont' (for all contaminant in name list)\n        - short name for group of geochemicals:\n            - 'environmental_conditions'\n            - 'chemical_composition'\n            - 'ONS':  non reduced electron acceptors (oxygen, nitrate, sulfate)\n            - 'ONSFe': selected electron acceptors  (oxygen, nitrate, sulfate + iron II)\n            - 'all_ea': all potential electron acceptors (non reduced &amp; reduced)\n            - 'NP': nutrients (nitrate, nitrite, phosphate)\n        See also file mibiscreen/data/name_data for lists of quantities\nverbose: Boolean\n    verbose flag (default False)\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.determine_quantities--output","title":"Output","text":"<pre><code>quantities: list\n    list of strings with names of selected quantities present in dataframe\nremainder: list\n    list of strings with names of selected quantities not present in dataframe\n</code></pre> Source code in <code>mibiscreen/data/set_data.py</code> <pre><code>def determine_quantities(cols,\n         name_list = 'all',\n         verbose = False,\n         ):\n    \"\"\"Select a subset of column names (from DataFrame).\n\n    Input\n    -----\n        cols: list\n            Names of quantities (column names) from pd.DataFrame\n        name_list: str or list of str, default is 'all'\n            quantities to extract from column names.\n\n            If a list of strings is provided, these will be selected from the list of column names (col)\n            If a string is provided, this is a short name for a specific group of quantities:\n                - 'all' (all quantities given in data frame except settings)\n                - short name for group of contaminants:\n                    - 'BTEX' (for benzene, toluene, ethylbenzene, xylene)\n                    - 'BTEXIIN' (for benzene, toluene, ethylbenzene, xylene,\n                                  indene, indane and naphthaline)\n                    - 'all_cont' (for all contaminant in name list)\n                - short name for group of geochemicals:\n                    - 'environmental_conditions'\n                    - 'chemical_composition'\n                    - 'ONS':  non reduced electron acceptors (oxygen, nitrate, sulfate)\n                    - 'ONSFe': selected electron acceptors  (oxygen, nitrate, sulfate + iron II)\n                    - 'all_ea': all potential electron acceptors (non reduced &amp; reduced)\n                    - 'NP': nutrients (nitrate, nitrite, phosphate)\n                See also file mibiscreen/data/name_data for lists of quantities\n        verbose: Boolean\n            verbose flag (default False)\n\n    Output\n    ------\n        quantities: list\n            list of strings with names of selected quantities present in dataframe\n        remainder: list\n            list of strings with names of selected quantities not present in dataframe\n\n    \"\"\"\n    if name_list == 'all':\n        ### choosing all column names except those of settings\n        list_names = list(set(cols) - set(names.settings))\n        if verbose:\n            print(\"Selecting all data columns except for those with settings.\")\n\n    elif isinstance(name_list, str):\n        if name_list in names.contaminants.keys():\n            verbose_text = \"Selecting specific group of contaminants:\"\n            list_names = names.contaminants[name_list].copy()\n            if (names.name_o_xylene in cols) and (names.name_pm_xylene in cols):\n                list_names.remove(names.name_xylene) # handling of xylene isomeres\n\n        elif name_list in names.geochemicals.keys():\n            verbose_text = \"Selecting specific group of geochemicals:\"\n            list_names = names.geochemicals[name_list].copy()\n\n        else:\n            verbose_text = \"Selecting single quantity:\"\n            list_names = [name_list]\n\n        if verbose:\n            print(verbose_text,*name_list,sep='\\n')\n\n    elif isinstance(name_list, list): # choosing specific list of column names except those of settings\n        if not all(isinstance(item, str) for item in name_list):\n            raise ValueError(\"Keyword 'name_list' needs to be a string or a list of strings.\")\n        list_names = name_list\n        if verbose:\n            print(\"Selecting all names from provided list.\")\n\n    else:\n        raise ValueError(\"Keyword 'name_list' needs to be a string or a list of strings.\")\n\n    quantities,_,remainder_list2 = compare_lists(cols,list_names)\n\n    if not quantities:\n        raise ValueError(\"No quantities from name list '{}' provided in data.\\\n                         Presumably data not in standardized format. \\\n                         Run 'standardize()' first.\".format(name_list))\n\n    if verbose:\n        print(\"Selected set of quantities: \", *quantities,sep='\\n')\n\n    if remainder_list2:\n        print(\"WARNING: quantities from name list not in data:\", *remainder_list2,sep='\\n')\n        print(\"Maybe data not in standardized format. Run 'standardize()' first.\")\n        print(\"_________________________________________________________________\")\n\n\n    return quantities,remainder_list2\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.extract_data","title":"<code>extract_data(data_frame, name_list, keep_setting_data=True, verbose=False)</code>","text":"<p>Extracting data of specified variables from dataframe.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements\nname_list: list of strings\n    list of column names to extract from dataframe\nkeep_setting_data: bool, default True\n    Whether to keep setting data in the DataFrame.\nverbose: Boolean\n    verbose flag (default False)\n</code></pre> <pre><code>data: pd.DataFrame\n    dataframe with the measurements\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.extract_data--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.extract_data--example","title":"Example:","text":"<p>To be added.</p> Source code in <code>mibiscreen/data/set_data.py</code> <pre><code>def extract_data(data_frame,\n                 name_list,\n                 keep_setting_data = True,\n                 verbose = False,\n                 ):\n    \"\"\"Extracting data of specified variables from dataframe.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements\n        name_list: list of strings\n            list of column names to extract from dataframe\n        keep_setting_data: bool, default True\n            Whether to keep setting data in the DataFrame.\n        verbose: Boolean\n            verbose flag (default False)\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            dataframe with the measurements\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    To be added.\n\n    \"\"\"\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = False)\n\n    quantities, _ = determine_quantities(cols,\n                                      name_list = name_list,\n                                      verbose = verbose)\n\n    if keep_setting_data:\n        settings,_,_ = compare_lists(cols,names.settings)\n        i1,quantities_without_settings,_ = compare_lists(quantities,settings)\n        columns_names = settings + quantities_without_settings\n\n    else:\n        columns_names = quantities\n\n    return data[columns_names]\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.extract_settings","title":"<code>extract_settings(data_frame, verbose=False)</code>","text":"<p>Extracting data of specified variables from dataframe.</p> <pre><code>data_frame: pandas.DataFrames\n    dataframe with the measurements\nverbose: Boolean\n    verbose flag (default False)\n</code></pre> <pre><code>data: pd.DataFrame\n    dataframe with settings\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.extract_settings--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.extract_settings--example","title":"Example:","text":"<p>To be added.</p> Source code in <code>mibiscreen/data/set_data.py</code> <pre><code>def extract_settings(data_frame,\n                     verbose = False,\n                     ):\n    \"\"\"Extracting data of specified variables from dataframe.\n\n    Args:\n    -------\n        data_frame: pandas.DataFrames\n            dataframe with the measurements\n        verbose: Boolean\n            verbose flag (default False)\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            dataframe with settings\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    To be added.\n\n    \"\"\"\n    ### check on correct data input format and extracting column names as list\n    data,cols= check_data_frame(data_frame,inplace = False)\n\n    settings,r1,r2 = compare_lists(cols,names.settings)\n\n    if verbose:\n        print(\"Settings available in data: \", settings)\n\n    return data[settings]\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.merge_data","title":"<code>merge_data(data_frames_list, how='outer', on=[names.name_sample], clean=True, **kwargs)</code>","text":"<p>Merging dataframes along columns on similar sample name.</p> <pre><code>data_frames_list: list of pd.DataFrame\n    list of dataframes with the measurements\nhow: str, default 'outer'\n    Type of merge to be performed.\n    corresponds to keyword in pd.merge()\n    {\u2018left\u2019, \u2018right\u2019, \u2018outer\u2019, \u2018inner\u2019, \u2018cross\u2019}, default \u2018outer\u2019\non: list, default \"sample_nr\"\n    Column name(s) to join on.\n    corresponds to keyword in pd.merge()\nclean: Boolean, default True\n    Whether to drop columns which are in all provided data_frames\n    (on which not to merge, potentially other settings than sample_name)\n**kwargs: dict\n    optional keyword arguments to be passed to pd.merge()\n</code></pre> <pre><code>data: pd.DataFrame\n    dataframe with the measurements\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.merge_data--raises","title":"Raises:","text":"<p>None (yet).</p>"},{"location":"reference/reference_data/#mibiscreen.data.set_data.merge_data--example","title":"Example:","text":"<p>To be added.</p> Source code in <code>mibiscreen/data/set_data.py</code> <pre><code>def merge_data(data_frames_list,\n               how='outer',\n               on=[names.name_sample],\n               clean = True,\n               **kwargs,\n               ):\n    \"\"\"Merging dataframes along columns on similar sample name.\n\n    Args:\n    -------\n        data_frames_list: list of pd.DataFrame\n            list of dataframes with the measurements\n        how: str, default 'outer'\n            Type of merge to be performed.\n            corresponds to keyword in pd.merge()\n            {\u2018left\u2019, \u2018right\u2019, \u2018outer\u2019, \u2018inner\u2019, \u2018cross\u2019}, default \u2018outer\u2019\n        on: list, default \"sample_nr\"\n            Column name(s) to join on.\n            corresponds to keyword in pd.merge()\n        clean: Boolean, default True\n            Whether to drop columns which are in all provided data_frames\n            (on which not to merge, potentially other settings than sample_name)\n        **kwargs: dict\n            optional keyword arguments to be passed to pd.merge()\n\n    Returns:\n    -------\n        data: pd.DataFrame\n            dataframe with the measurements\n\n    Raises:\n    -------\n    None (yet).\n\n    Example:\n    -------\n    To be added.\n\n    \"\"\"\n    if len(data_frames_list)&lt;2:\n        raise ValueError('Provide List of DataFrames.')\n\n\n    data_merge = data_frames_list[0]\n    for data_add in data_frames_list[1:]:\n        if clean:\n            intersection,remainder_list1,remainder_list2 = compare_lists(\n                data_merge.columns.to_list(),data_add.columns.to_list())\n            intersection,remainder_list1,remainder_list2 = compare_lists(intersection,on)\n            data_add = data_add.drop(labels = remainder_list1+remainder_list2,axis = 1)\n        data_merge = pd.merge(data_merge,data_add, how=how, on=on,**kwargs)\n        # complete data set, where values of porosity are added (otherwise nan)\n\n    return data_merge\n</code></pre>"},{"location":"reference/reference_data/#mibiscreen.data.unit_settings","title":"<code>unit_settings</code>","text":"<p>Unit specifications of data!</p> <p>File containing unit specifications of quantities and parameters measured in groundwater samples useful for biodegredation and bioremediation analysis.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_visualize/","title":"<code>mibiscreen.visualize</code> API reference","text":"<p>mibiscreen module for data visualization.</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.activity","title":"<code>activity</code>","text":"<p>Activity plot.</p> <p>@author: alraune</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.activity.activity","title":"<code>activity(data, save_fig=False, **kwargs)</code>","text":"<p>Function creating activity plot.</p> <p>Activity plot showing scatter of total number of metabolites vs total concentration of contaminant per well with color coding of NA traffic lights: red/yellow/green corresponding to no natural attenuation going on (red), limited/unknown NA activity (yellow) or active natural attenuation (green)</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.activity.activity--input","title":"Input","text":"<pre><code>data: list or pandas.DataFrame\n    quantities required in plot:\n        - total concentration of contaminants per sample\n        - total count of metabolites per sample\n        - traffic light on NA activity per sample\n    if DataFrame, it contains the three required quantities with their standard names\n    if list of arrays: the three quantities are given order above\n    if list of pandas-Series, quantities given in standard names\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string. =\n**kwargs: dict\n    dictionary with plot settings\n</code></pre>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.activity.activity--output","title":"Output","text":"<pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibiscreen/visualize/activity.py</code> <pre><code>def activity(\n        data,\n        save_fig=False,\n        **kwargs,\n        ):\n    \"\"\"Function creating activity plot.\n\n    Activity plot showing scatter of total number of metabolites vs total concentration\n    of contaminant per well with color coding of NA traffic lights: red/yellow/green\n    corresponding to no natural attenuation going on (red), limited/unknown NA activity (yellow)\n    or active natural attenuation (green)\n\n    Input\n    ----------\n        data: list or pandas.DataFrame\n            quantities required in plot:\n                - total concentration of contaminants per sample\n                - total count of metabolites per sample\n                - traffic light on NA activity per sample\n            if DataFrame, it contains the three required quantities with their standard names\n            if list of arrays: the three quantities are given order above\n            if list of pandas-Series, quantities given in standard names\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string. =\n        **kwargs: dict\n            dictionary with plot settings\n\n    Output\n    -------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    ### ---------------------------------------------------------------------------\n    ### Handling of input data\n    if isinstance(data, pd.DataFrame):\n        meta_count = data[name_metabolites_variety].values\n        tot_cont = data[name_total_contaminants].values\n        well_color = data[name_na_traffic_light].values\n    elif isinstance(data, list) and len(data)&gt;=3:\n        if isinstance(data[0], pd.Series) and isinstance(data[1], pd.Series) and isinstance(data[2], pd.Series):\n            for series in data:\n                if series.name == name_metabolites_variety:\n                    meta_count = series.values\n                if series.name == name_total_contaminants:\n                    tot_cont = series.values\n                if series.name == name_na_traffic_light:\n                    well_color = series.values\n        elif isinstance(data[0], (np.ndarray, list)):\n            tot_cont = data[0]\n            meta_count = data[1]\n            well_color = data[2]\n            # print(\"MATCH\")\n        else:\n            raise ValueError(\"List elements in data must be lists, np.arrays or pd.series.\")\n        if len(tot_cont) != len(meta_count) or len(tot_cont) != len(well_color):\n            raise ValueError(\"Provided arrays/lists/series of data must have the same length.\")\n    else:\n        raise ValueError(\"Data needs to be DataFrame or list of at least three lists/np.arrays/pd.series.\")\n\n    if len(tot_cont) &lt;= 1:\n        raise ValueError(\"Too little data for activity plot. At least two values per quantity required.\")\n\n    ### ---------------------------------------------------------------------------\n    ### Creating Figure\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(tot_cont,\n               meta_count,\n               c=well_color,\n               zorder = 3,\n               s = settings['markersize'],\n               ec = settings['ec'],\n               lw = settings['lw'],\n               )\n\n    ### generate legend labels\n    if \"green\" in well_color:\n        ax.scatter([], [],\n                   label=\"available\",\n                   c=\"green\",\n                   s = settings['markersize'],\n                   ec = settings['ec'],\n                   lw = settings['lw'],\n                   )\n    if \"y\" in well_color:\n        ax.scatter([], [],\n                   label=\"unknown\",\n                   c=\"y\",\n                   s = settings['markersize'],\n                   ec = settings['ec'],\n                   lw = settings['lw'],\n                   )\n    if \"red\" in well_color:\n        ax.scatter([], [],\n                   label=\"depleted\",\n                   c=\"red\",\n                   s = settings['markersize'],\n                   ec = settings['ec'],\n                   lw = settings['lw'],\n                   )\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n    ax.set_xlabel(r\"Concentration contaminants [$\\mu$g/L]\",fontsize=settings['textsize'])\n    ax.set_ylabel(\"Metabolite variety\", fontsize=settings['textsize'])\n    ax.grid()\n    ax.minorticks_on()\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=settings['textsize'])\n    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=settings['textsize'])\n    plt.legend(title = 'Electron acceptors:',loc =settings['loc'], fontsize=settings['textsize'] )\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig, ax\n</code></pre>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.ordination_plot","title":"<code>ordination_plot</code>","text":"<p>Ordination plot.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.ordination_plot.ordination_plot","title":"<code>ordination_plot(ordination_output, plot_loadings=True, plot_scores=True, rescale_loadings_scores=False, adjust_text=True, scale_focus='loadings', axis_ranges=False, save_fig=False, **kwargs)</code>","text":"<p>Function creating ordination plot.</p> <p>Based on ordination analysis providing ordination loadings and scores.</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.ordination_plot.ordination_plot--input","title":"Input","text":"<pre><code>ordination_output : Dictionary\n    contains ordination results:\n        - as numpy arrays; ordination loading and scores\n        - names of the samples and the Environmental and Species variables\n        - method : String (pca, cca, rda) The ordination method used in the analysis.\nplot_loadings : Boolean; default is True\n    flag to plot the ordination loadings\nplot_scores : Boolean; default is True\n    flag to plot the ordiantion scores\nrescale_loadings_scores : Boolean; default is False\n    flag to rescale loadings and scores to have a loading close to 1\nadjust_text : Boolean, default is True\n    flag to perform automized adjustment of text labes of loadings and scores to avoid overlap\nscale_focus : String, default is \"loadings\"\n    flag to specify if scaling focusses on either 'loadings' or 'scores' or 'none'.\naxis_ranges : Boolean or list/array of 4 values, default is False,\n    if array or list it gives fixed x and y axis dimensions [x_min, x_maxm y_min, y_max]\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string.\n**kwargs: dict\n    dictionary with plot settings (e.g. fonts, arrow specifics, etc)\n</code></pre>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.ordination_plot.ordination_plot--output","title":"Output","text":"<pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibiscreen/visualize/ordination_plot.py</code> <pre><code>def ordination_plot(ordination_output,\n                    plot_loadings = True,\n                    plot_scores = True,\n                    rescale_loadings_scores = False,\n                    adjust_text = True,\n                    scale_focus = \"loadings\",\n                    axis_ranges = False,\n                    save_fig=False,\n                    **kwargs,\n                    ):\n    \"\"\"Function creating ordination plot.\n\n    Based on ordination analysis providing ordination loadings and scores.\n\n    Input\n    -----\n        ordination_output : Dictionary\n            contains ordination results:\n                - as numpy arrays; ordination loading and scores\n                - names of the samples and the Environmental and Species variables\n                - method : String (pca, cca, rda) The ordination method used in the analysis.\n        plot_loadings : Boolean; default is True\n            flag to plot the ordination loadings\n        plot_scores : Boolean; default is True\n            flag to plot the ordiantion scores\n        rescale_loadings_scores : Boolean; default is False\n            flag to rescale loadings and scores to have a loading close to 1\n        adjust_text : Boolean, default is True\n            flag to perform automized adjustment of text labes of loadings and scores to avoid overlap\n        scale_focus : String, default is \"loadings\"\n            flag to specify if scaling focusses on either 'loadings' or 'scores' or 'none'.\n        axis_ranges : Boolean or list/array of 4 values, default is False,\n            if array or list it gives fixed x and y axis dimensions [x_min, x_maxm y_min, y_max]\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string.\n        **kwargs: dict\n            dictionary with plot settings (e.g. fonts, arrow specifics, etc)\n\n    Output\n    ------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    ### ---------------------------------------------------------------------------\n    ### check on completeness of input ordination_output\n\n    if not isinstance(ordination_output,dict):\n        raise TypeError(\"Input data must be given as dictionary with standard output of ordination methods.\")\n\n    if \"loadings_independent\" not in ordination_output.keys():\n        raise KeyError(\"Input dictionary does not contain data on loadings ('loadings_independent')\")\n    else:\n        loadings_independent = ordination_output[\"loadings_independent\"]\n        names_independent = ordination_output[\"names_independent\"]\n        if len(loadings_independent) == 0:\n            loadings_independent = np.array([[],[]]).T\n\n    if \"scores\" not in ordination_output.keys():\n        raise KeyError(\"Input dictionary does not contain data on scores ('scores')\")\n    else:\n        scores = ordination_output[\"scores\"]\n\n    if \"sample_index\" not in ordination_output.keys():\n        sample_index = np.arange(scores.shape[0])\n    else:\n        sample_index = ordination_output[\"sample_index\"]\n\n    if \"loadings_dependent\" in ordination_output.keys():\n        loadings_dependent = ordination_output[\"loadings_dependent\"]\n        names_dependent = ordination_output[\"names_dependent\"]\n        if len(loadings_dependent) == 0:\n            loadings_dependent = np.array([[],[]]).T\n        loadings = np.append(loadings_independent, loadings_dependent, axis=0)\n    else:\n        loadings = loadings_independent\n\n    ### ---------------------------------------------------------------------------\n    ### Rescale ordination_output given plot specifics\n\n    # Determing the largest values in the PCA scores.\n    max_load = np.max(np.abs(loadings))\n    max_score = np.max(np.abs(scores))\n\n    if max_load &gt; 1 or rescale_loadings_scores:\n        # loadings = loadings / (max_load*1.05)\n        loadings = loadings / (max_load)\n    if max_score &gt; 1 or rescale_loadings_scores:\n        # scores = scores / (max_score*1.05)\n        scores = scores / (max_score)\n\n    if axis_ranges is not False:\n        # Takes the given axis dimensions for both ordination axes\n        x_lim_neg,x_lim_pos,y_lim_neg,y_lim_pos = axis_ranges\n    else:\n        # Adjusts axis dimensions for both ordination axes to ordination_output\n        if plot_scores and plot_loadings:\n            # When plotting both scores and loadings, scores or loadings are scaled\n            # depending on the extent of the other. Depends on the input of Scale_focus.\n            if scale_focus == \"loadings\":\n                scores = scores * np.max(np.abs(loadings))\n            elif scale_focus == \"scores\":\n                loadings = loadings *  np.max(np.abs(scores))\n            full_coords = np.append(loadings, scores, axis=0)\n        elif plot_loadings:\n            full_coords = loadings\n        else:\n            full_coords = scores\n\n        x_lim_pos = 0.11*np.ceil(np.max(full_coords[:,0])*10)\n        y_lim_pos = 0.11*np.ceil(np.max(full_coords[:,1])*10)\n        x_lim_neg = 0.11*np.floor(np.min(full_coords[:,0])*10)\n        y_lim_neg = 0.11*np.floor(np.min(full_coords[:,1])*10)\n\n    ### ---------------------------------------------------------------------------\n    ### Create Figure, finally!\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    texts = []\n\n    # Plotting the ordination scores by iterating over every coordinate\n    # in the scores array, if the Plot_scores parameter is set to true.\n    if plot_scores:\n        for i, (x, y) in enumerate(scores):\n            plt.scatter(x, y,\n                        color=settings['score_color'],\n                        marker = settings['score_marker'],\n                        s = settings['score_marker_size'],\n                        facecolor=settings['score_facecolor'],\n                        edgecolor=settings['score_edgecolor'],\n                        zorder = 7,\n                        )\n            # Plotting the name of the scores and storing it in a list for the purpose of adjusting the position later\n            tex = plt.text(x, y, sample_index[i], color='black', fontsize = settings['score_fontsize'],zorder = 9)\n            texts.append(tex)\n\n    if plot_loadings:\n        # Plots independent (=environmental) and dependent (=species) variables\n        # with different colours and text formatting.\n        for i, (x, y) in enumerate(loadings_independent):\n            plt.arrow(0, 0, x, y,\n                      color = settings['arrow_color_independent'],\n                      width = settings['arrow_width'],\n                      head_length = settings['arrow_head_length'],\n                      head_width = settings['arrow_head_width'],\n                      zorder = 10,\n                      )\n            #Plotting the name of the loading\n            tex = plt.text(x, y, names_independent[i],\n                            color='black',\n                            fontstyle = settings['fontstyle_independent'],\n                            weight = settings['weight_independent'],\n                            fontsize = settings['loading_fontsize'],\n                            zorder = 11,\n                            )\n            texts.append(tex)\n        if \"loadings_dependent\" in ordination_output.keys():\n            for i, (x, y) in enumerate(loadings_dependent):\n                plt.arrow(0, 0, x, y,\n                          color=settings['arrow_color_dependent'],\n                          width = settings['arrow_width'],\n                          head_length = settings['arrow_head_length'],\n                          head_width = settings['arrow_head_width'],\n                          zorder = 8,\n                          )\n                tex = plt.text(x, y, names_dependent[i],\n                                color='black',\n                                fontstyle = settings['fontstyle_dependent'],\n                                weight = settings['weight_dependent'],\n                                fontsize = settings['loading_fontsize'],\n                                zorder = 9,\n                                )\n                # and storing it in a list for the purpose of adjusting the position later\n                texts.append(tex)\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    # Plotting lines that indicate the origin\n    plt.plot([-1, 1], [0, 0], color='grey', linewidth=0.75, linestyle='--')\n    plt.plot([0, 0], [-1, 1], color='grey', linewidth=0.75, linestyle='--')\n\n    # Setting the x and y axis limits with the previously determined values\n    plt.xlim(x_lim_neg, x_lim_pos)\n    plt.ylim(y_lim_neg, y_lim_pos)\n    plt.tick_params(axis=\"both\",which=\"major\",labelsize=settings['label_fontsize'])\n\n    if ordination_output[\"method\"]=='pca':\n        percent_explained = ordination_output[\"percent_explained\"]\n        plt.xlabel('PC1 ({:.1f}%)'.format(percent_explained[0]), fontsize = settings['label_fontsize'])\n        plt.ylabel('PC2 ({:.1f}%)'.format(percent_explained[1]), fontsize = settings['label_fontsize'])\n    else:\n        plt.xlabel('ordination axis 1', fontsize = settings['label_fontsize'])\n        plt.ylabel('ordination axis 2', fontsize = settings['label_fontsize'])\n\n    if adjust_text:\n        try:\n            from adjustText import adjust_text\n            adjust_text(texts)\n        except ImportError:\n            print(\"WARNING: packages 'adjustText' not installed.\")\n            print(\" For making text adjustment, install package 'adjustText'.\")\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n\n    if isinstance(settings['title'],str):\n        plt.title(settings['title'],fontsize = settings['label_fontsize'])\n\n    plt.tight_layout()\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Figure saved to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig, ax\n</code></pre>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.stable_isotope_plots","title":"<code>stable_isotope_plots</code>","text":"<p>Linear regression plots for stable isotope analysis in mibiscreen.</p> <p>@author: Alraune Zech</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.stable_isotope_plots.Keeling_plot","title":"<code>Keeling_plot(concentration, delta, coefficients, relative_abundance=None, save_fig=False, **kwargs)</code>","text":"<p>Creating a Keeling plot.</p> <p>A Keeling plot is an approach to identify the isotopic composition of a contaminating source from measured concentrations and isotopic composition (delta) of a target species in the mix of the source and a pool. It is based on the linear relationship of the concentration and the delta-value which are measured over time or across a spatial interval.</p> <p>The plot shows the inverse concentration data against the delta-values along the linear regression line. For gaining the regression coefficients perform a linear fitting or run</p> <pre><code>Keeling_regression() [in the module analysis]\n</code></pre> <p>The parameter of interest, the delta (or relative_abundance, respectively) of the source quantity is the intercept of linear fit with the y-axis, or in other words, the absolute value of the linear fit function.</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.stable_isotope_plots.Keeling_plot--input","title":"Input","text":"<pre><code>c_mix : np.array, pd.dataframe\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta_mix : np.array, pd.dataframe (same length as c_mix)\n    relative isotope ratio (delta-value) of target substance\nrelative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n    if not None it replaces delta_mix in the inverse estimation and plotting\n    relative abundance of target substance\ncoefficients : tuple of lenght 2\n    containing coefficients of the linear fit\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string. =\n**kwargs: dict\n    dictionary with plot settings\n</code></pre> <pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibiscreen/visualize/stable_isotope_plots.py</code> <pre><code>def Keeling_plot(concentration,\n                 delta,\n                 coefficients,\n                 relative_abundance = None,\n                 save_fig = False,\n                 **kwargs,\n                 ):\n    \"\"\"Creating a Keeling plot.\n\n    A Keeling plot is an approach to identify the isotopic composition of a\n    contaminating source from measured concentrations and isotopic composition\n    (delta) of a target species in the mix of the source and a pool. It is based\n    on the linear relationship of the concentration and the delta-value\n    which are measured over time or across a spatial interval.\n\n    The plot shows the inverse concentration data against the delta-values\n    along the linear regression line. For gaining the regression coefficients\n    perform a linear fitting or run\n\n        Keeling_regression() [in the module analysis]\n\n    The parameter of interest, the delta (or relative_abundance, respectively)\n    of the source quantity is the intercept of linear fit with the y-axis,\n    or in other words, the absolute value of the linear fit function.\n\n    Input\n    -----\n        c_mix : np.array, pd.dataframe\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta_mix : np.array, pd.dataframe (same length as c_mix)\n            relative isotope ratio (delta-value) of target substance\n        relative_abundance : None or np.array, pd.dataframe (same length as c_mix), default None\n            if not None it replaces delta_mix in the inverse estimation and plotting\n            relative abundance of target substance\n        coefficients : tuple of lenght 2\n            containing coefficients of the linear fit\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string. =\n        **kwargs: dict\n            dictionary with plot settings\n\n    Returns:\n    --------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    if relative_abundance is not None:\n        y = relative_abundance\n        text = 'x'\n    else:\n        y = delta\n        text = r\"\\delta\"\n\n    x = 1/concentration\n\n    ### ---------------------------------------------------------------------------\n    ### create plot\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(x,y, marker=settings['marker'], zorder = 3,label = 'data')\n\n    ### ---------------------------------------------------------------------------\n    ### plot linear regression trend line\n\n    polynomial = np.poly1d(coefficients)\n    trendline_x = np.linspace(min(0,np.min(x)),np.max(x), 100)\n    trendline_y = polynomial(trendline_x)\n\n    ax.plot(trendline_x, trendline_y, color= settings['fit_color'], label='linear fit')\n    ax.text(0.5, 0.1,\n            r\"${}_{{source}} = {:.3f}$\".format(text,coefficients[1]),\n             bbox=dict(boxstyle=\"round\", facecolor='w'),#,alpha=0.5)\n             transform=ax.transAxes,\n             fontsize=settings['fontsize'])\n    ax.scatter(0,coefficients[1],\n               c = settings['intercept_color'],\n               zorder = 3,\n               label = r'intercept: ${}_{{source}}$'.format(text),\n               )\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    ax.set_xlabel('Inverse concentration $1/c$',fontsize=settings['fontsize'])\n    ax.set_ylabel('${}$'.format(text),fontsize=settings['fontsize'])\n    ax.grid(True,zorder = 0)\n    ax.set_xlim([0-x[-1]*0.05, x[-1]*1.05])\n    ax.legend(loc =settings['loc'], fontsize=settings['fontsize'])\n    if isinstance(settings['title'],str):\n        ax.set_title(settings['title'],fontsize = settings['fontsize'])\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig,ax\n</code></pre>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.stable_isotope_plots.Lambda_plot","title":"<code>Lambda_plot(delta_C, delta_H, coefficients, save_fig=False, **kwargs)</code>","text":"<p>Creating a Lambda plot.</p> <p>A Lambda plot shows the \u03b413C versus \u03b42H signatures of a chemical compound. Relative changes in the carbon and hydrogen isotope ratios can indicate the occurrence of specific enzymatic degradation reactions. The relative changes are indicated by the lambda-H/C value which is the slope of the linear regression of hydrogen versus carbon isotope signatures. For gaining the regression coefficients perform a linear fitting or run</p> <pre><code> Lambda_regression() [in the module analysis]\n</code></pre> Lambda-values linking to specific enzymatic reactions <p>To be added!</p> <p>Details provided in Vogt et al. [2016, 2020].</p> References <p>C. Vogt, C. Dorer, F. Musat, and H. H. Richnow. Multi-element isotope fractionation concepts to characterize the biodegradation of hydrocarbons - from enzymes to the environment. Current Opinion in Biotechnology, 41:90\u201398, 2016. C. Vogt, F. Musat, and H.-H. Richnow. Compound-Specific Isotope Analysis for Studying the Biological Degradation of Hydrocarbons. In Anaerobic Utilization of Hydrocarbons, Oils, and Lipids, pages 285-321. Springer Nature Switzerland, 2020.</p> <p>A. Fischer, I. Herklotz, S. Herrmann, M. Thullner, S. A. Weelink, A. J. Stams, M. Schl \u0308omann, H.-H. Richnow, and C. Vogt. Combined Carbon and Hydrogen Isotope Fractionation Investigations for Elucidating Benzene Biodegradation Pathways. Environmental Science and Technology, 42:4356\u20134363, 2008.</p> <p>S. Kuemmel, F.-A. Herbst, A. Bahr, M. Arcia Duarte, D. H. Pieper, N. Jehmlich, J. Seifert, M. Von Bergen, P. Bombach, H. H. Richnow, and C. Vogt. Anaerobic naphthalene degradation by sulfate-reducing Desulfobacteraceae from various anoxic aquifers. FEMS Microbiology Ecology, 91(3), 2015.</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.stable_isotope_plots.Lambda_plot--input","title":"Input","text":"<pre><code>delta_C : np.array, pd.series\n    relative isotope ratio (delta-value) of carbon of target molecule\ndelta_H : np.array, pd.series (same length as delta_C)\n    relative isotope ratio (delta-value) of hydrogen of target molecule\ncoefficients : tuple of lenght 2\n    containing coefficients of the linear fit\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string.\n**kwargs: dict\n    dictionary with plot settings\n</code></pre> <pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibiscreen/visualize/stable_isotope_plots.py</code> <pre><code>def Lambda_plot(delta_C,\n                delta_H,\n                coefficients,\n                save_fig = False,\n                **kwargs,\n                ):\n    \"\"\"Creating a Lambda plot.\n\n    A Lambda plot shows the \u03b413C versus \u03b42H signatures of a chemical compound.\n    Relative changes in the carbon and hydrogen isotope ratios can indicate the\n    occurrence of specific enzymatic degradation reactions. The relative changes\n    are indicated by the lambda-H/C value which is the slope of the linear\n    regression of hydrogen versus carbon isotope signatures. For gaining the\n    regression coefficients perform a linear fitting or run\n\n         Lambda_regression() [in the module analysis]\n\n    Lambda-values linking to specific enzymatic reactions:\n        To be added!\n\n    Details provided in Vogt et al. [2016, 2020].\n\n    References:\n        C. Vogt, C. Dorer, F. Musat, and H. H. Richnow. Multi-element isotope\n        fractionation concepts to characterize the biodegradation of hydrocarbons\n        - from enzymes to the environment. Current Opinion in Biotechnology,\n        41:90\u201398, 2016.\n        C. Vogt, F. Musat, and H.-H. Richnow. Compound-Specific Isotope Analysis\n        for Studying the Biological Degradation of Hydrocarbons. In Anaerobic\n        Utilization of Hydrocarbons, Oils, and Lipids, pages 285-321.\n        Springer Nature Switzerland, 2020.\n\n        A. Fischer, I. Herklotz, S. Herrmann, M. Thullner, S. A. Weelink,\n        A. J. Stams, M. Schl \u0308omann, H.-H. Richnow, and C. Vogt. Combined Carbon\n        and Hydrogen Isotope Fractionation Investigations for Elucidating\n        Benzene Biodegradation Pathways. Environmental Science and Technology,\n        42:4356\u20134363, 2008.\n\n        S. Kuemmel, F.-A. Herbst, A. Bahr, M. Arcia Duarte, D. H. Pieper,\n        N. Jehmlich, J. Seifert, M. Von Bergen, P. Bombach, H. H. Richnow,\n        and C. Vogt. Anaerobic naphthalene degradation by sulfate-reducing\n        Desulfobacteraceae from various anoxic aquifers.\n        FEMS Microbiology Ecology, 91(3), 2015.\n\n    Input\n    -----\n        delta_C : np.array, pd.series\n            relative isotope ratio (delta-value) of carbon of target molecule\n        delta_H : np.array, pd.series (same length as delta_C)\n            relative isotope ratio (delta-value) of hydrogen of target molecule\n        coefficients : tuple of lenght 2\n            containing coefficients of the linear fit\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string.\n        **kwargs: dict\n            dictionary with plot settings\n\n    Returns:\n    --------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(delta_C, delta_H, marker=settings['marker'],zorder = 3,label= 'data')\n\n    ### ---------------------------------------------------------------------------\n    ### plot linear regression trend line\n\n    polynomial = np.poly1d(coefficients)\n    trendline_x = np.linspace(np.min(delta_C), np.max(delta_C), 100)\n    trendline_y = polynomial(trendline_x)\n    ax.plot(trendline_x, trendline_y, color= settings['fit_color'], label='linear fit')\n    ax.text(0.4, 0.1,\n             r\"$\\Lambda = {:.2f}$\".format(coefficients[0]),\n             bbox=dict(boxstyle=\"round\", facecolor='w'),#,alpha=0.5),\n             transform=ax.transAxes,\n             fontsize=settings['fontsize'])\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    ax.grid(True,zorder = 0)\n    ax.set_xlabel(r'$\\delta^{{13}}$C')\n    ax.set_ylabel(r'$\\delta^2$H')\n    ax.legend(loc =settings['loc'], fontsize=settings['fontsize'])\n    if isinstance(settings['title'],str):\n        ax.set_title(settings['title'],fontsize = settings['fontsize'])\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig,ax\n</code></pre>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.stable_isotope_plots.Rayleigh_fractionation_plot","title":"<code>Rayleigh_fractionation_plot(concentration, delta, coefficients, save_fig=False, **kwargs)</code>","text":"<p>Creating a Rayleigh fractionation plot.</p> <p>Rayleigh fractionation is a common application to characterize the removal of a substance from a finite pool using stable isotopes. It is based on the change in the isotopic composition of the pool due to different kinetics of the change in lighter and heavier isotopes.</p> <p>We follow the most simple approach assuming that the substance removal follows first-order kinetics, where the rate coefficients for the lighter and heavier isotopes of the substance differ due to kinetic isotope fractionation effects. The isotopic composition of the remaining substance in the pool will change over time, leading to the so-called Rayleigh fractionation.</p> <p>The plot shows the log-transformed concentration data against the delta-values along the linear regression line. For gaining the regression coefficients perform a linear fitting or run</p> <pre><code>Rayleigh_fractionation() [in the module analysis]\n</code></pre> <p>The parameter of interest, the kinetic fractionation factor (epsilon or alpha -1) of the removal process is the slope of the the linear trend line.</p>"},{"location":"reference/reference_visualize/#mibiscreen.visualize.stable_isotope_plots.Rayleigh_fractionation_plot--input","title":"Input","text":"<pre><code>concentration : np.array, pd.series\n    total molecular mass/molar concentration of target substance\n    at different locations (at a time) or at different times (at one location)\ndelta : np.array, pd.series (same length as concentration)\n    relative isotope ratio (delta-value) of target substance\ncoefficients : tuple of lenght 2\n    containing coefficients of the linear fit\nsave_fig: Boolean or string, optional, default is False.\n    Flag to save figure to file with name provided as string. =\n**kwargs: dict\n    dictionary with plot settings\n</code></pre> <pre><code>fig : Figure object\n    Figure object of created activity plot.\nax :  Axes object\n    Axes object of created activity plot.\n</code></pre> Source code in <code>mibiscreen/visualize/stable_isotope_plots.py</code> <pre><code>def Rayleigh_fractionation_plot(concentration,\n                                delta,\n                                coefficients,\n                                save_fig = False,\n                                **kwargs,\n                                ):\n    \"\"\"Creating a Rayleigh fractionation plot.\n\n    Rayleigh fractionation is a common application to characterize the removal\n    of a substance from a finite pool using stable isotopes. It is based on the\n    change in the isotopic composition of the pool due to different kinetics of\n    the change in lighter and heavier isotopes.\n\n    We follow the most simple approach assuming that the substance removal follows\n    first-order kinetics, where the rate coefficients for the lighter and heavier\n    isotopes of the substance differ due to kinetic isotope fractionation effects.\n    The isotopic composition of the remaining substance in the pool will change\n    over time, leading to the so-called Rayleigh fractionation.\n\n    The plot shows the log-transformed concentration data against the delta-values\n    along the linear regression line. For gaining the regression coefficients\n    perform a linear fitting or run\n\n        Rayleigh_fractionation() [in the module analysis]\n\n    The parameter of interest, the kinetic fractionation factor (epsilon or alpha -1)\n    of the removal process is the slope of the the linear trend line.\n\n    Input\n    -----\n        concentration : np.array, pd.series\n            total molecular mass/molar concentration of target substance\n            at different locations (at a time) or at different times (at one location)\n        delta : np.array, pd.series (same length as concentration)\n            relative isotope ratio (delta-value) of target substance\n        coefficients : tuple of lenght 2\n            containing coefficients of the linear fit\n        save_fig: Boolean or string, optional, default is False.\n            Flag to save figure to file with name provided as string. =\n        **kwargs: dict\n            dictionary with plot settings\n\n    Returns:\n    --------\n        fig : Figure object\n            Figure object of created activity plot.\n        ax :  Axes object\n            Axes object of created activity plot.\n\n    \"\"\"\n    settings = copy.copy(DEF_settings)\n    settings.update(**kwargs)\n\n    x = np.log(concentration)\n    ### ---------------------------------------------------------------------------\n    ### create plot\n    fig, ax = plt.subplots(figsize=settings['figsize'])\n    ax.scatter(x,delta, marker=settings['marker'], zorder = 3,label = 'data')\n\n    ### ---------------------------------------------------------------------------\n    ### plot linear regression trend line\n\n    polynomial = np.poly1d(coefficients)\n    trendline_x = np.linspace(np.min(x), np.max(x), 100)\n    trendline_y = polynomial(trendline_x)\n    ax.plot(trendline_x, trendline_y, color= settings['fit_color'], label='linear fit')\n    ax.text(0.1, 0.1,\n             r\"$\\epsilon = 1-\\alpha = {:.3f}$\".format(coefficients[0]),\n             bbox=dict(boxstyle=\"round\", facecolor='w'),#,alpha=0.5),\n             transform=ax.transAxes,\n             fontsize=settings['fontsize'])\n\n    ### ---------------------------------------------------------------------------\n    ### Adapt plot optics\n\n    ax.set_xlabel(r'log-concentration $\\ln c$',fontsize=settings['fontsize'])\n    ax.set_ylabel(r'$\\delta$',fontsize=settings['fontsize'])\n    ax.grid(True,zorder = 0)\n    ax.legend(loc =settings['loc'], fontsize=settings['fontsize'])\n    if isinstance(settings['title'],str):\n        ax.set_title(settings['title'],fontsize = settings['fontsize'])\n    fig.tight_layout()\n\n    ### ---------------------------------------------------------------------------\n    ### Save figure to file if file path provided\n    if save_fig is not False:\n        try:\n            plt.savefig(save_fig,dpi = settings['dpi'])\n            print(\"Save Figure to file:\\n\", save_fig)\n        except OSError:\n            print(\"WARNING: Figure could not be saved. Check provided file path and name: {}\".format(save_fig))\n\n    return fig,ax\n</code></pre>"}]}